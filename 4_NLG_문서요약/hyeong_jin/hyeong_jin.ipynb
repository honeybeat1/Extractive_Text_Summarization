{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXS8BohW9mHg",
        "outputId": "f015be99-936d-437c-d3b0-9daff24b2497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/SKT-AI/KoBART\n",
            "  Cloning https://github.com/SKT-AI/KoBART to /tmp/pip-req-build-yc_l605j\n",
            "  Running command git clone -q https://github.com/SKT-AI/KoBART /tmp/pip-req-build-yc_l605j\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.22-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from kobart==0.5.1) (1.3.5)\n",
            "Collecting pytorch-lightning==1.2.1\n",
            "  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
            "\u001b[K     |████████████████████████████████| 814 kB 35.8 MB/s \n",
            "\u001b[?25hCollecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 15 kB/s \n",
            "\u001b[?25hCollecting transformers==4.3.3\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 43.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (1.21.5)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 45.6 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (2.8.0)\n",
            "Collecting PyYAML!=5.4.*,>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->kobart==0.5.1) (3.10.0.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 49.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (4.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (3.6.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->kobart==0.5.1) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 55.1 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart==0.5.1) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart==0.5.1) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 66.2 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.22\n",
            "  Downloading botocore-1.24.22-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 43.0 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.22->boto3->kobart==0.5.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->kobart==0.5.1) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->kobart==0.5.1) (2018.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart==0.5.1) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart==0.5.1) (7.1.2)\n",
            "Building wheels for collected packages: kobart, future\n",
            "  Building wheel for kobart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobart: filename=kobart-0.5.1-py3-none-any.whl size=9562 sha256=c2271bbd771ab400ac658fc8fe6583735a4c070b0aae4cda75f485a13f2021a5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ucutq9o7/wheels/6e/55/c4/bd4fede223bc304089ac8da2a2099a69db3fcd4b0e853383f5\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=446b7eac91420d72560431914588446e171dd6ea3aaaeca2b431fd630850cedb\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built kobart future\n",
            "Installing collected packages: urllib3, multidict, frozenlist, yarl, jmespath, asynctest, async-timeout, aiosignal, fsspec, botocore, aiohttp, torch, tokenizers, sacremoses, s3transfer, PyYAML, future, transformers, pytorch-lightning, boto3, kobart\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 boto3-1.21.22 botocore-1.24.22 frozenlist-1.3.0 fsspec-2022.2.0 future-0.18.2 jmespath-1.0.0 kobart-0.5.1 multidict-6.0.2 pytorch-lightning-1.2.1 s3transfer-0.5.2 sacremoses-0.0.49 tokenizers-0.10.3 torch-1.7.1 transformers-4.3.3 urllib3-1.25.11 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/SKT-AI/KoBART #egg=kobart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KUfwH5tXtEyQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os \n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import re\n",
        "\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58DHYlQkt95N",
        "outputId": "4eb18319-ad3c-4808-b02c-7a87bec59e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHXL22kYyWxV",
        "outputId": "539b9987-cb1a-4b12-c1b7-47d6e09d05ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7kzv5U25HUQ"
      },
      "source": [
        "### 원본 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "j7Yjhg1D1s76"
      },
      "outputs": [],
      "source": [
        "csv_test = pd.read_csv(\"/content/drive/MyDrive/NLP/sports_news_data - sports_news_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3U1QMZqj2Lcd",
        "outputId": "ad2c612c-764c-4973-b16c-128a142cbfcc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e3aaf27b-2059-406a-bc69-0cc0d2860945\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>PUBLISH_DT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>스털링 다이빙 논란 종결?… “오른쪽 다리 접촉 있었잖아”</td>\n",
              "      <td>[스포탈코리아] 유럽축구연맹(UEFA) 유로 2020 심판위원장 로베르토 로세티가 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‘디 마리아 없다’ 유로X코파 베스트11, 이탈리아만 7명</td>\n",
              "      <td>[스포탈코리아] 유로 2020과 코파 아메리카 2021로 베스트11을 만든다면 어떤...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‘슈퍼컴퓨터 예측’ 맨시티 우승-맨유 4위… 토트넘은 ‘6위’</td>\n",
              "      <td>[스포탈코리아] 새 시즌이 시작하기도 전에 슈퍼컴퓨터가 예상한 순위가 나왔다.\\n\\...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“이재성, 완벽한 프로… 마인츠서 성공할 것” 킬 디렉터의 애정 듬뿍 응원</td>\n",
              "      <td>[스포탈코리아] 홀슈타인 킬 우베 스토버 디렉터가 이재성을 향해 응원 메시지를 띄웠...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‘홈킷과 딴판’ 바르사 팬들, NEW 어웨이 셔츠 호평… “가장 좋아하는 색!”</td>\n",
              "      <td>[스포탈코리아] FC 바르셀로나가 새 시즌 원정 유니폼을 공개했다. 팬들은 만족스럽...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>긴급 수혈된 바르사 NO.9, 1년 반 만에 떠난다… ‘EPL행 유력’</td>\n",
              "      <td>[스포탈코리아] FC 바르셀로나는 새 시즌을 앞두고 선수단 정리가 한창이다. 잉여 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[김남구의 유럽통신] 황의조, 손흥민 소속사와 손잡다… CAA Base와 계약</td>\n",
              "      <td>[스포탈코리아=파리(프랑스)] 황의조(지롱댕 드 보르도)가 한국 선수로는 3번째로 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"메시 종신은 축복!\"…스폰서 5년 더 보장, 바르셀로나 함박웃음</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34)가 FC바르셀로나에 남는다. 연봉을 절반 삭감하지...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[오피셜] 눈물 흘렸던 '37세 전설' 로번, 두 번째 현역 은퇴 발표</td>\n",
              "      <td>[스포탈코리아] 네덜란드 축구스타 아르연 로번(37)이 현역 은퇴를 밝혔다. \\n\\...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100세' 메시팬 할아버지, 748골 수기 작성…메시도 감사 인사</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34)는 프로 데뷔하고 748골을 터뜨렸다. 전산화 하...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>475억원이면 맨유 떠난다…시메오네의 픽, 부활한 린가드</td>\n",
              "      <td>[스포탈코리아] 스페인 프리메라리가 챔피언 아틀레티코 마드리드가 부활한 제시 린가드...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>토트넘, 케인 대체자 ‘세리에A 21골+810억 골잡이’ 찾았다</td>\n",
              "      <td>[스포탈코리아] 토트넘 홋스퍼가 해리 케인(27) 이탈을 대비하고 있다. 이탈리아 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1,585억에 케인 불발 맨시티, 329경기 294골 킬러 영입 추진</td>\n",
              "      <td>[스포탈코리아] 맨체스터 시티가 확실한 킬러를 찾기 위해 분주하다. \\n\\n맨시티는...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>맨유 관심 프랑스 18세 미드필더, ‘레알이나 바르사 갈 건데요’</td>\n",
              "      <td>[스포탈코리아] ‘잉글랜드보다 스페인이 더 끌리네요’\\n\\n빅클럽들이 군침을 흘리고...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>“메시, 월드컵 4회 우승해도 마라도나 못 넘어” 전설의 주장</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34, FC바르셀로나)가 선배인 故 디에고 마라도와 또...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>모리뉴, 손흥민 전 동료에게 “동물이다”</td>\n",
              "      <td>[스포탈코리아] AS로마 수장 조세 모리뉴(58)가 손흥민(29, 토트넘 홋스퍼)의...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>도르트문트, 첼시의 홀란 영입 제안 거절(英 스카이스포츠)</td>\n",
              "      <td>[스포탈코리아] 보루시아 도르트문트가 뜨거운 감자 엘링 홀란(20)을 붙잡는다.\\n...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>레노버, 인터 밀란과 파트너십 강화… 유니폼 스폰서로 나서</td>\n",
              "      <td>[스포탈코리아] 세계 1위 PC 및 스마트 디바이스 업체 레노버가 인터 밀란과 파트...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>‘다시 돌아와!’ 웨스트햄, 임대 전설 쓰고 떠난 린가드 영입 추진</td>\n",
              "      <td>[스포탈코리아] 웨스트햄 유나이티드가 제시 린가드(맨체스터 유나이티드) 영입에 원하...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>바르셀로나 충격 요구 : 그리즈만 = 사울+200억원, 사울+선수 1명</td>\n",
              "      <td>[스포탈코리아] FC바르셀로나가 아틀레티코 마드리드에 트레이드를 요구했다. \\n\\n...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3aaf27b-2059-406a-bc69-0cc0d2860945')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3aaf27b-2059-406a-bc69-0cc0d2860945 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3aaf27b-2059-406a-bc69-0cc0d2860945');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           TITLE  \\\n",
              "0               스털링 다이빙 논란 종결?… “오른쪽 다리 접촉 있었잖아”   \n",
              "1               ‘디 마리아 없다’ 유로X코파 베스트11, 이탈리아만 7명   \n",
              "2             ‘슈퍼컴퓨터 예측’ 맨시티 우승-맨유 4위… 토트넘은 ‘6위’   \n",
              "3      “이재성, 완벽한 프로… 마인츠서 성공할 것” 킬 디렉터의 애정 듬뿍 응원   \n",
              "4   ‘홈킷과 딴판’ 바르사 팬들, NEW 어웨이 셔츠 호평… “가장 좋아하는 색!”   \n",
              "5        긴급 수혈된 바르사 NO.9, 1년 반 만에 떠난다… ‘EPL행 유력’   \n",
              "6    [김남구의 유럽통신] 황의조, 손흥민 소속사와 손잡다… CAA Base와 계약   \n",
              "7           \"메시 종신은 축복!\"…스폰서 5년 더 보장, 바르셀로나 함박웃음   \n",
              "8        [오피셜] 눈물 흘렸던 '37세 전설' 로번, 두 번째 현역 은퇴 발표   \n",
              "9           100세' 메시팬 할아버지, 748골 수기 작성…메시도 감사 인사   \n",
              "10               475억원이면 맨유 떠난다…시메오네의 픽, 부활한 린가드   \n",
              "11           토트넘, 케인 대체자 ‘세리에A 21골+810억 골잡이’ 찾았다   \n",
              "12        1,585억에 케인 불발 맨시티, 329경기 294골 킬러 영입 추진   \n",
              "13          맨유 관심 프랑스 18세 미드필더, ‘레알이나 바르사 갈 건데요’   \n",
              "14            “메시, 월드컵 4회 우승해도 마라도나 못 넘어” 전설의 주장   \n",
              "15                        모리뉴, 손흥민 전 동료에게 “동물이다”   \n",
              "16              도르트문트, 첼시의 홀란 영입 제안 거절(英 스카이스포츠)   \n",
              "17              레노버, 인터 밀란과 파트너십 강화… 유니폼 스폰서로 나서   \n",
              "18         ‘다시 돌아와!’ 웨스트햄, 임대 전설 쓰고 떠난 린가드 영입 추진   \n",
              "19       바르셀로나 충격 요구 : 그리즈만 = 사울+200억원, 사울+선수 1명   \n",
              "\n",
              "                                              CONTENT  PUBLISH_DT  \n",
              "0   [스포탈코리아] 유럽축구연맹(UEFA) 유로 2020 심판위원장 로베르토 로세티가 ...  2021-07-15  \n",
              "1   [스포탈코리아] 유로 2020과 코파 아메리카 2021로 베스트11을 만든다면 어떤...  2021-07-15  \n",
              "2   [스포탈코리아] 새 시즌이 시작하기도 전에 슈퍼컴퓨터가 예상한 순위가 나왔다.\\n\\...  2021-07-15  \n",
              "3   [스포탈코리아] 홀슈타인 킬 우베 스토버 디렉터가 이재성을 향해 응원 메시지를 띄웠...  2021-07-15  \n",
              "4   [스포탈코리아] FC 바르셀로나가 새 시즌 원정 유니폼을 공개했다. 팬들은 만족스럽...  2021-07-15  \n",
              "5   [스포탈코리아] FC 바르셀로나는 새 시즌을 앞두고 선수단 정리가 한창이다. 잉여 ...  2021-07-15  \n",
              "6   [스포탈코리아=파리(프랑스)] 황의조(지롱댕 드 보르도)가 한국 선수로는 3번째로 ...  2021-07-15  \n",
              "7   [스포탈코리아] 리오넬 메시(34)가 FC바르셀로나에 남는다. 연봉을 절반 삭감하지...  2021-07-15  \n",
              "8   [스포탈코리아] 네덜란드 축구스타 아르연 로번(37)이 현역 은퇴를 밝혔다. \\n\\...  2021-07-15  \n",
              "9   [스포탈코리아] 리오넬 메시(34)는 프로 데뷔하고 748골을 터뜨렸다. 전산화 하...  2021-07-15  \n",
              "10  [스포탈코리아] 스페인 프리메라리가 챔피언 아틀레티코 마드리드가 부활한 제시 린가드...  2021-07-15  \n",
              "11  [스포탈코리아] 토트넘 홋스퍼가 해리 케인(27) 이탈을 대비하고 있다. 이탈리아 ...  2021-07-15  \n",
              "12  [스포탈코리아] 맨체스터 시티가 확실한 킬러를 찾기 위해 분주하다. \\n\\n맨시티는...  2021-07-15  \n",
              "13  [스포탈코리아] ‘잉글랜드보다 스페인이 더 끌리네요’\\n\\n빅클럽들이 군침을 흘리고...  2021-07-15  \n",
              "14  [스포탈코리아] 리오넬 메시(34, FC바르셀로나)가 선배인 故 디에고 마라도와 또...  2021-07-15  \n",
              "15  [스포탈코리아] AS로마 수장 조세 모리뉴(58)가 손흥민(29, 토트넘 홋스퍼)의...  2021-07-15  \n",
              "16  [스포탈코리아] 보루시아 도르트문트가 뜨거운 감자 엘링 홀란(20)을 붙잡는다.\\n...  2021-07-15  \n",
              "17  [스포탈코리아] 세계 1위 PC 및 스마트 디바이스 업체 레노버가 인터 밀란과 파트...  2021-07-15  \n",
              "18  [스포탈코리아] 웨스트햄 유나이티드가 제시 린가드(맨체스터 유나이티드) 영입에 원하...  2021-07-15  \n",
              "19  [스포탈코리아] FC바르셀로나가 아틀레티코 마드리드에 트레이드를 요구했다. \\n\\n...  2021-07-15  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_test.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhpUnNfR63sq"
      },
      "source": [
        "### 전처리\n",
        "- 중복 및 결측치 제거\n",
        "- 크롤링 상에서 생긴 쓸모 없는 문구 처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QgS0iTJ8QT0F"
      },
      "outputs": [],
      "source": [
        "def preprocess(string):\n",
        "    str_list = string.split('\\n\\n') # \\n\\n 기준으로 분리\n",
        "    str_list[0] = str_list[0].replace('[스포탈코리아] ', '') # [스포탈코리아] 삭제\n",
        "    \n",
        "    result = []\n",
        "    for strg in str_list:\n",
        "        strg = re.sub(r'\\([^)]*\\)|\\[[^)]*\\]|\\<[^)]*\\>', ' ', strg) # 괄호와 그 안에 문자 제거\n",
        "\n",
        "        if '기자' in strg: # 기자 이름이 들어간 경우 기자이름 삭제\n",
        "            strg = strg.split('기자')[-1]\n",
        "        if '다.' in strg: # 문장 단위로 분리\n",
        "            strg = strg.split('. ')\n",
        "            for s in strg:\n",
        "                if s != '':\n",
        "                    result.append(s)\n",
        "            \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "uMpyTPRiQwWb"
      },
      "outputs": [],
      "source": [
        "def special(str_list):\n",
        "    regex = r\"[^가-힣a-zA-Z0-9 ]\" # 특수 문자 제거\n",
        "    for i in range(len(str_list)):\n",
        "        str_list[i] = re.sub(regex, '', str_list[i])\n",
        "\n",
        "    return str_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "MQSj-oMeQ5Yb"
      },
      "outputs": [],
      "source": [
        "def special_title(string):\n",
        "    regex = r\"[^가-힣a-zA-Z0-9 ]\" # 특수 문자 제거\n",
        "    string = re.sub(regex, '', string)\n",
        "\n",
        "    return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SA9s6Ts52cYZ"
      },
      "outputs": [],
      "source": [
        "trimmed_data=csv_test.dropna().copy()\n",
        "  \n",
        "idx = trimmed_data['CONTENT'].drop_duplicates().index\n",
        "trimmed_data = trimmed_data.loc[idx]\n",
        "\n",
        "idx = trimmed_data['TITLE'].drop_duplicates().index\n",
        "trimmed_data = trimmed_data.loc[idx]\n",
        "\n",
        "trimmed_data['CONTENT'] = trimmed_data['CONTENT'].apply(preprocess)\n",
        "trimmed_data['CONTENT'] = trimmed_data['CONTENT'].apply(special)\n",
        "trimmed_data['TITLE'] = trimmed_data['TITLE'].apply(special_title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWzYDTh748dO",
        "outputId": "706fa21b-d54c-4ca9-f454-64f4482a153b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8995"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trimmed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY0DpSOn95HL",
        "outputId": "a74c2840-cfcb-4a06-ea8c-1adf544f6067"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['성남FC가 만17세 2004년생 수비수 김지수와 준프로 계약을 체결했다',\n",
              " '김지수는 192cm84kg의 체격에 제공권이 좋고 시야가 넓어 대인 방어와 패스에 능하다',\n",
              " ' 김지수는 성남FC U15 U18에서 활약하며 성남의 유망주로 이름을 알렸으며 꾸준히 연령별 대표팀에도 이름을 올리고 있다',\n",
              " 'U15 크로아티아 국제 축구대회와 AFC U16 챔피언십 예선 참여 2021년 경기도 꿈나무 축구대회 우승 2021년 제29회 백록기 전국 고교 축구대회에서 우승 주역으로 베스트 영플레이어상을 수상한 김지수는 성남FC U18 풍생고에서 성장 가능성이 큰 선수로 꼽혀왔다 구단은 유소년 육성에 집중 투자하면서 구단 유스 프로 계약의 증가와 구단 최초 준프로 계약 등 점차 가시적인 성과를 내고 있으며 꾸준한 유소년 시스템 투자와 유망주 발굴을 통해 구단의 지속적 성장의 기틀을 다질 예정이다 김남일 감독은 풍생고 경기를 꾸준히 보면서 김지수를 눈여겨봤었다',\n",
              " '책임감 있고 안정적인 경기 운영을 하는 것이 눈에 띄었다',\n",
              " '김지수가 성남에서 첫 프로 도전을 하는 만큼 열심히 준비해서 경기장에서 본인의 잠재력을 마음껏 펼치길 바란다라고 밝혔다 김지수는 이번 1차 전지훈련에서 프로팀 형들과 훈련을 한 것도 영광이었는데 바로 계약까지 하게 된 게 아직 꿈만 같다',\n",
              " '성남 유스 출신 선수라는 책임감이 생겼다',\n",
              " '2차 전지훈련 동안 선수 형들에게 많이 배우고 열심히 준비해서 팀에 도움이 되고 싶다라고 밝혔다 그는 성남FC 협력병원인 분당베스트병원에서 메디컬테스트를 마쳤고 2차 전지훈련지인 부산 기장으로 출발하여 본격적인 2022시즌 준비에 나선다']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmed_data['CONTENT'].iloc[8991]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOrftvJW63Dt"
      },
      "source": [
        "- 띄어쓰기 및 불용어 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_oPnfM62iN",
        "outputId": "d82d1327-f40b-4229-da3f-543d2617e11b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sNfaAWH6fTI",
        "outputId": "643672ab-3501-4ff1-83c2-45f0676d618d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ranks.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Korean stop words: 677\n"
          ]
        }
      ],
      "source": [
        "# 한국어 불용어 리스트 크롤링\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.ranks.nl/stopwords/korean\"\n",
        "response = requests.get(url, verify = False)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    content = soup.select_one('#article178ebefbfb1b165454ec9f168f545239 > div.panel-body > table > tbody > tr')\n",
        "    stop_words=[]\n",
        "    for x in content.strings:\n",
        "        x=x.strip()\n",
        "        if x:\n",
        "            stop_words.append(x)\n",
        "    print(f\"# Korean stop words: {len(stop_words)}\")\n",
        "else:\n",
        "    print(response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lCXhA4D_WBO",
        "outputId": "325a2351-8e78-4e43-ebe4-a4bf5c05dd6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8995/8995 [08:40<00:00, 17.28it/s]\n"
          ]
        }
      ],
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "for i in tqdm(range(len(trimmed_data))):\n",
        "  temp_data = okt.morphs(trimmed_data[\"TITLE\"].iloc[i])\n",
        "  temp_list = []\n",
        "\n",
        "  for word in temp_data:\n",
        "    if word in stop_words: continue\n",
        "    temp_list.append(word)\n",
        "  \n",
        "  trimmed_data[\"TITLE\"].iloc[i] = \" \".join(temp_list)\n",
        "\n",
        "  temp_list = []\n",
        "  for sentence in trimmed_data[\"CONTENT\"].iloc[i]:\n",
        "    temp_data = okt.morphs(sentence)\n",
        "    temp_sentecne_list = []\n",
        "    \n",
        "    for word in temp_data:\n",
        "      if word in stop_words: continue\n",
        "      temp_sentecne_list.append(word)\n",
        "    \n",
        "    temp_sentence = \" \".join(temp_sentecne_list)\n",
        "    temp_list.append(temp_sentence)\n",
        "  \n",
        "  trimmed_data[\"CONTENT\"].iloc[i] = temp_list\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFLassY0Dtlz",
        "outputId": "3411243e-1316-41d1-9ed2-4cae2edaa4d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['이름 값 만 화려한 맨유 워스트 11 공개 됐다',\n",
              " '영국 매체 익스 프레 스 는 7일 알렉스 퍼거슨 경 은퇴 후 맨유 워스트 11 선정 했다',\n",
              " '퍼거슨 경 은퇴 후 맨유 워스트 11 에는 이름 값 만 화려한 선수 많았다',\n",
              " '공 격진 에는 멤피스 데 파이 라다 멜 팔카오 알 렉시스 산체스 포함 됐다',\n",
              " '데 파이는 많은 기대 받고 PSV 아인트호벤 떠나 맨유 유니폼 입었다',\n",
              " '보여준 없었다',\n",
              " '최악 경기 력 선보이면서 실패 작 낙인 찍혔다',\n",
              " '인간계 최강 이라고 불렸던 팔카오 도 맨유 쓴맛 봤다',\n",
              " '공 격진 무게 감 실어 줄 이라는 엄청난 기대는 산산조각 났다',\n",
              " '산체스 도 맨유 역대 최악 입 중 한 명 꼽힌다',\n",
              " '주급 7억 이라는 명성 맞지 않는 경기 력 질타 피하 지 못 했다',\n",
              " '레알 마드리드 합류 한 앙헬 디 마리아 아약스 엄청난 퍼포먼스 업고 이적 한 도니 판 더 비크 도 맨유 워스트 11 불명예 안았다',\n",
              " '이외 프레드 마 테오 다르 미안 해리 이어 타일러 블랙 켓 마르코스 로호 빅토르 발데스 이름 올렸다']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmed_data['CONTENT'].iloc[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "eKmPpqXaYO15"
      },
      "outputs": [],
      "source": [
        "trimmed_data.to_csv('/content/drive/MyDrive/NLP/trimmed_sport_data.csv', sep=',', na_rep='NaN', index = False) # do not write index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNwQ2Y1q4_py"
      },
      "source": [
        "### 수정한 파일 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "40KHB61ZYsDT"
      },
      "outputs": [],
      "source": [
        "trimmed_data = pd.read_csv(\"/content/drive/MyDrive/NLP/trimmed_sport_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u1n3vqdbY3Jg",
        "outputId": "81eb68cc-2d31-4e94-cea5-fcbe787a6e12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fe4c3c73-defb-4f55-a761-1afd2d265f9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>PUBLISH_DT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아</td>\n",
              "      <td>['유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>디 마리아 없다 유로 X 코파 베스트 11 이탈리아 만 7 명</td>\n",
              "      <td>['지난달 시작 된 유로 코파 아메리카 11일 끝 막 내렸다', '이탈리아 는 결승...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>슈퍼컴퓨터 예측 맨시티 우승 맨유 4 위 토트넘 은 6 위</td>\n",
              "      <td>['새 시즌 시작 하기도 전 슈퍼컴퓨터 예상 한 순위 나왔다', '영국 매체 스포츠...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이재성 완벽한 프로 마인츠 서 성공할 킬 디렉터 애정 듬뿍 응원</td>\n",
              "      <td>['홀슈타인 킬 우베 스토 버 디렉터 이재성 향 해 응원 메시지 띄웠다', '이재성...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>홈킷 딴판 바르사 팬 NEW 웨이 셔츠 호평 가장 좋아하는 색</td>\n",
              "      <td>['FC 바르셀로나 새 시즌 원정 유니폼 공개 했다', '팬 은 만족스럽다는 반응 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe4c3c73-defb-4f55-a761-1afd2d265f9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe4c3c73-defb-4f55-a761-1afd2d265f9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe4c3c73-defb-4f55-a761-1afd2d265f9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 TITLE  \\\n",
              "0         스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아   \n",
              "1   디 마리아 없다 유로 X 코파 베스트 11 이탈리아 만 7 명   \n",
              "2     슈퍼컴퓨터 예측 맨시티 우승 맨유 4 위 토트넘 은 6 위   \n",
              "3  이재성 완벽한 프로 마인츠 서 성공할 킬 디렉터 애정 듬뿍 응원   \n",
              "4   홈킷 딴판 바르사 팬 NEW 웨이 셔츠 호평 가장 좋아하는 색   \n",
              "\n",
              "                                             CONTENT  PUBLISH_DT  \n",
              "0  ['유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 ...  2021-07-15  \n",
              "1  ['지난달 시작 된 유로 코파 아메리카 11일 끝 막 내렸다', '이탈리아 는 결승...  2021-07-15  \n",
              "2  ['새 시즌 시작 하기도 전 슈퍼컴퓨터 예상 한 순위 나왔다', '영국 매체 스포츠...  2021-07-15  \n",
              "3  ['홀슈타인 킬 우베 스토 버 디렉터 이재성 향 해 응원 메시지 띄웠다', '이재성...  2021-07-15  \n",
              "4  ['FC 바르셀로나 새 시즌 원정 유니폼 공개 했다', '팬 은 만족스럽다는 반응 ...  2021-07-15  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no71C-gm-b3r",
        "outputId": "058bb343-93f5-45b8-fda5-da6054441529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TITLE                              스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아\n",
            "CONTENT       [유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나...\n",
            "PUBLISH_DT                                           2021-07-15\n",
            "Name: 0, dtype: object\n",
            "['유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나온 판정 논란 정심 이라고 공언 했다', '지난 8일 잉글랜드 덴마크 는 유로 2020 4 강 결승 티켓 두고 격돌 했다', '연장 접전 끝 잉글랜드 21 이겼다', '경기 후 논란 불거졌다', '11 팽팽 하던 연장 전반 12분 라 힘 스털링 드리블 돌파 하던 중 요아킴 멜레 마티아스 옌센 사이 넘어졌다', '심판 은 곧장 페널티 스팟 찍었다', '비디오 판독 실과 의견 나눈 뒤 에도 원심 유지 했다', '페널티킥 얻은 잉글랜드 는 해리 케인 실축 했지만 흐른 볼 밀어 넣어 결승 티켓 따냈다', '장면 두고 갑론 박 펼쳐졌다', '스털링 은 경기 후 인터뷰 명백한 페널티킥 이라고 주장 했지만 전문가 의견 은 달랐다', '조제 모리뉴 AS 로마 감독 아르 센 벵거 전 아스널 감독 은 페널티킥 아니다고 입 모았다', '많은 이야기 흘러나오는 가운데 유로 2020 심판 위원장 로세티 오심 아니라는 입장 내놨다', '로세티 위원장 은 14일 영국 매체 가디언 인터뷰 주심 은 5 번 수비수 주목 했다', '수비수 볼 터치 하지 않았다고 봤다', '멜레 오른쪽 다리 스털링 오른쪽 다리 접촉 한 확인 했다', '접촉 강도 논 할 수 있지만 는 항상 심판 의사결정 과정 중심 되길 바란다고 밝혔다', '로세티 위원장 심판 대표 해 의견 냈지만 오심 이라고 생각 하는 받아들일지는 미지수 다', '스털링 은 평소 에도 다이빙 논란 시 달려왔고 많은 머릿속 다이버 라는 인식 가득하기 때문 이다']\n",
            "0\n",
            "유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나온 판정 논란 정심 이라고 공언 했다\n",
            "1\n",
            "지난 8일 잉글랜드 덴마크 는 유로 2020 4 강 결승 티켓 두고 격돌 했다\n",
            "2\n",
            "연장 접전 끝 잉글랜드 21 이겼다\n",
            "3\n",
            "경기 후 논란 불거졌다\n",
            "4\n",
            "11 팽팽 하던 연장 전반 12분 라 힘 스털링 드리블 돌파 하던 중 요아킴 멜레 마티아스 옌센 사이 넘어졌다\n",
            "5\n",
            "심판 은 곧장 페널티 스팟 찍었다\n",
            "6\n",
            "비디오 판독 실과 의견 나눈 뒤 에도 원심 유지 했다\n",
            "7\n",
            "페널티킥 얻은 잉글랜드 는 해리 케인 실축 했지만 흐른 볼 밀어 넣어 결승 티켓 따냈다\n",
            "8\n",
            "장면 두고 갑론 박 펼쳐졌다\n",
            "9\n",
            "스털링 은 경기 후 인터뷰 명백한 페널티킥 이라고 주장 했지만 전문가 의견 은 달랐다\n",
            "10\n",
            "조제 모리뉴 AS 로마 감독 아르 센 벵거 전 아스널 감독 은 페널티킥 아니다고 입 모았다\n",
            "11\n",
            "많은 이야기 흘러나오는 가운데 유로 2020 심판 위원장 로세티 오심 아니라는 입장 내놨다\n",
            "12\n",
            "로세티 위원장 은 14일 영국 매체 가디언 인터뷰 주심 은 5 번 수비수 주목 했다\n",
            "13\n",
            "수비수 볼 터치 하지 않았다고 봤다\n",
            "14\n",
            "멜레 오른쪽 다리 스털링 오른쪽 다리 접촉 한 확인 했다\n",
            "15\n",
            "접촉 강도 논 할 수 있지만 는 항상 심판 의사결정 과정 중심 되길 바란다고 밝혔다\n",
            "16\n",
            "로세티 위원장 심판 대표 해 의견 냈지만 오심 이라고 생각 하는 받아들일지는 미지수 다\n",
            "17\n",
            "스털링 은 평소 에도 다이빙 논란 시 달려왔고 많은 머릿속 다이버 라는 인식 가득하기 때문 이다\n"
          ]
        }
      ],
      "source": [
        "data_row = trimmed_data.iloc[0]\n",
        "print(data_row)\n",
        "\n",
        "text = data_row['CONTENT']\n",
        "print(text)\n",
        "\n",
        "for i, sentence in enumerate(text):\n",
        "  print(i)\n",
        "  print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwR_0Y2Uyc0g"
      },
      "source": [
        "#Extractive summarization - Matchsum\n",
        "### Dataset & Dataloader 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "r7YNbMt9ybeV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "V93s8-DRniiR"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data,\n",
        "      tokenizer,\n",
        "      text_max_token_len: int = 512,\n",
        "      summary_max_token_len : int = 128\n",
        "  ):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.text_max_token_len = text_max_token_len\n",
        "    self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    cls_token = torch.tensor([0])\n",
        "    sep_token = torch.tensor([1])\n",
        "    \n",
        "    data_row = self.data.iloc[index]\n",
        "    text = data_row['CONTENT']\n",
        "    \n",
        "    total_text_ids = torch.tensor([])\n",
        "    for sentence in text:\n",
        "      text_encoding_sentence = self.tokenizer(\n",
        "          sentence,\n",
        "          add_special_tokens = True,\n",
        "          return_tensors = \"pt\"\n",
        "      )\n",
        "      sentence_input_ids = text_encoding_sentence['input_ids'].flatten()\n",
        "      sentence_input_ids = torch.cat([cls_token,sentence_input_ids,sep_token]) # 각 문장 앞에 cls 토큰 추가, 각 문장 뒤에 sep 토큰 추가\n",
        "      total_text_ids = torch.cat([total_text_ids,sentence_input_ids])\n",
        "    \n",
        "    cur_length = len(total_text_ids)\n",
        "    if cur_length > self.text_max_token_len:\n",
        "      total_text_ids = total_text_ids[:self.text_max_token_len] # 길이가 넘치면 자른다\n",
        "    else:\n",
        "      padding_list = torch.tensor([3]*(self.text_max_token_len - cur_length)) # 길이가 모자라면 padding token 을 채운다\n",
        "      total_text_ids = torch.cat([total_text_ids,padding_list])\n",
        "    \n",
        "    total_text_ids = total_text_ids.int()\n",
        "\n",
        "    labels = data_row['TITLE']\n",
        "    summary_encoding = self.tokenizer(\n",
        "        labels,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "\n",
        "    labels_ids = summary_encoding['input_ids'].flatten()\n",
        "    \n",
        "    cur_length = len(labels_ids)\n",
        "    if cur_length +2 > self.summary_max_token_len:  # 현재 토큰 길이+2(cls,sep) 가 총 길이\n",
        "      labels_ids = labels_ids[:self.summary_max_token_len-2]\n",
        "      labels_ids = torch.cat([cls_token,labels_ids,sep_token])\n",
        "    else : \n",
        "      padding_list =torch.tensor([3]*(self.summary_max_token_len-cur_length-2))\n",
        "      labels_ids =  torch.cat([cls_token,labels_ids,sep_token,padding_list])\n",
        "\n",
        "    return dict(text_input_ids = total_text_ids, labels_input_ids = labels_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNA-2QR7uXMl",
        "outputId": "4f100df1-e616-49f2-afce-3b69e2f2e00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /content/.cache/kobart_base_tokenizer_cased_cf74400bce.zip\n"
          ]
        }
      ],
      "source": [
        "tokenizer = get_kobart_tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "hK1C6_KKrL7v"
      },
      "outputs": [],
      "source": [
        "whole_dataset = CustomDataset(trimmed_data,tokenizer)\n",
        "\n",
        "train_set_num = len(trimmed_data)//5*4\n",
        "train_dataset , test_dataset = random_split(whole_dataset, [train_set_num,len(trimmed_data)-train_set_num])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 8, shuffle=True)\n",
        "test_dataloader =  DataLoader(test_dataset, batch_size = 8, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKJb-DcKynhV"
      },
      "source": [
        "# Model-Load\n",
        "- Encoder -> KoBART\n",
        "- GLM 을 제외한 제일 성능 좋은 모델이고 한국어로 train이 되어 있어 선정함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiYH-dn7VYLv"
      },
      "outputs": [],
      "source": [
        "class MatchSum(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, candidate_num, hidden_size=768):\n",
        "        super(MatchSum, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.candidate_num  = candidate_num\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def forward(self, text_id, summary_id):\n",
        "        \n",
        "        batch_size = text_id.size(0)\n",
        "        pad_id = 3 \n",
        "\n",
        "        # get document embedding\n",
        "        input_mask = ~(text_id == pad_id)\n",
        "        out = self.encoder(text_id, attention_mask=input_mask)['hidden_states'][-1] # last layer\n",
        "        doc_emb = out[:, 0, :]\n",
        "        assert doc_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "        \n",
        "        # get summary embedding\n",
        "        input_mask = ~(summary_id == pad_id)\n",
        "        out = self.encoder(summary_id, attention_mask=input_mask)['hidden_states'][-1] # last layer\n",
        "        summary_emb = out[:, 0, :]\n",
        "        assert summary_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "\n",
        "        # get summary score\n",
        "        summary_score = torch.cosine_similarity(summary_emb, doc_emb, dim=-1)\n",
        "\n",
        "        # get candidate embedding\n",
        "        candidate_id = get_candidate_id(text_id, self.candidate_num)\n",
        "        candidate_id = candidate_id.view(-1, candidate_id.size(-1))\n",
        "        input_mask = ~(candidate_id == pad_id)\n",
        "        out = self.encoder(candidate_id, attention_mask=input_mask)[0]\n",
        "        candidate_emb = out[:, 0, :].view(batch_size, self.candidate_num, self.hidden_size)  # [batch_size, candidate_num, hidden_size]\n",
        "        assert candidate_emb.size() == (batch_size, self.candidate_num, self.hidden_size)\n",
        "        \n",
        "        # get candidate score\n",
        "        doc_emb = doc_emb.unsqueeze(1).expand_as(candidate_emb)\n",
        "        score = torch.cosine_similarity(candidate_emb, doc_emb, dim=-1) # [batch_size, candidate_num]\n",
        "        golden_list = torch.argmax(score,dim=1)\n",
        "        assert score.size() == (batch_size, self.candidate_num)\n",
        "\n",
        "        return {'score': score, 'summary_score': summary_score, 'golden_summary':candidate_emb[:,golden_list,:]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Jbgz4x5jeF"
      },
      "outputs": [],
      "source": [
        "class MarginRankingLoss():      \n",
        "    \n",
        "    def __init__(self, margin, score=None, summary_score=None):\n",
        "        super(MarginRankingLoss, self).__init__()\n",
        "        self._init_param_map(score=score, summary_score=summary_score)\n",
        "        self.margin = margin\n",
        "        self.loss_func = torch.nn.MarginRankingLoss(margin)\n",
        "\n",
        "    def get_loss(self, score, summary_score):\n",
        "        \n",
        "        # equivalent to initializing TotalLoss to 0\n",
        "        # here is to avoid that some special samples will not go into the following for loop\n",
        "        ones = torch.ones(score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss = loss_func(score, score, ones)\n",
        "\n",
        "        # candidate loss\n",
        "        n = score.size(1)\n",
        "        for i in range(1, n):\n",
        "            pos_score = score[:, :-i]\n",
        "            neg_score = score[:, i:]\n",
        "            pos_score = pos_score.contiguous().view(-1)\n",
        "            neg_score = neg_score.contiguous().view(-1)\n",
        "            ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "            loss_func = torch.nn.MarginRankingLoss(self.margin * i)\n",
        "            TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "\n",
        "        # gold summary loss\n",
        "        pos_score = summary_score.unsqueeze(-1).expand_as(score)\n",
        "        neg_score = score\n",
        "        pos_score = pos_score.contiguous().view(-1)\n",
        "        neg_score = neg_score.contiguous().view(-1)\n",
        "        ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "        \n",
        "        return TotalLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw4XrmYb3zpd"
      },
      "outputs": [],
      "source": [
        "# https://pypi.org/project/rouge-score/\n",
        "!pip install rouge-score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
        "                      'The quick brown dog jumps on the log.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vOs9-SBfjPr"
      },
      "outputs": [],
      "source": [
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3cvXctQgK6l"
      },
      "outputs": [],
      "source": [
        "text_encoding.to(device)\n",
        "outputs = model(**text_encoding,output_hidden_states = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxsohGkCCvm2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcIcbmwnyWEZ"
      },
      "outputs": [],
      "source": [
        "class rdass:\n",
        "  def __init__(self,model):\n",
        "    self.model = model\n",
        "  \n",
        "  def __call__(self, text = None, label = None, answer = None):\n",
        "    vector_text = self.model(text).detach() # vector_d\n",
        "    vector_label = self.model(label).detach() # vector_r\n",
        "    vector_answer = self.model(answer).detach() # vector_p\n",
        "\n",
        "    score_pr = torch.cosine_similarity(vector_answer,vector_label)\n",
        "    score_pd = torch.cosine_similarity(vector_answer,vector_text)\n",
        "\n",
        "    return (score_pr+score_pd)/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLOBXCEnjxIh"
      },
      "outputs": [],
      "source": [
        "class sbert:        # tokenizer 통합된 version\n",
        "    def __init__(self,model,device):\n",
        "        self.model = model\n",
        "        for param in self.model.parameters():\n",
        "        param.requires_grad = False\n",
        "        \n",
        "        model.to(device)\n",
        "    \n",
        "    def __call__(self,inputs_id,attention_mask):\n",
        "        outputs = self.model(\n",
        "            inputs_id = inputs_id, \n",
        "            token_type_ids = token_type_ids,\n",
        "            attention_mask = attention_mask\n",
        "            )\n",
        "        \n",
        "        hidden_states = outputs['hidden_states']\n",
        "        return hidden_states[-1][:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DelT9Z9wfbVi"
      },
      "outputs": [],
      "source": [
        "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
        "summary_model = MatchSum(encoder = model, candidate_num = 5, hidden_size=768) # hidden_size == vocab size?\n",
        "\n",
        "model_for_eval = sbert(model = ,device)\n",
        "metric = rdass(model_for_eval)\n",
        "\n",
        "N_EPOCHS = 3\n",
        "optimizer = SGD(model.parameters(),lr =0.0001)\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer,T_0 = 1,T_mult = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmtCKyr2D0YE"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "summary_model.to(device)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "    print(f\"*****Epoch {epoch} Total Step {len(train_dataloader)}*****\")\n",
        "    total_loss, batch_loss, batch_step = 0,0,0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch_step+=1\n",
        "        text_input_ids = batch[\"text_input_ids\"].to(device)        \n",
        "        label_input_ids = batch[\"label_inputs_ids\"].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        output = summary_model.forward(text_input_ids, label_input_ids)\n",
        "        loss = MarginRankingLoss(output[\"score\"],output[\"summary_score\"])\n",
        "\n",
        "        # loss 계산\n",
        "        loss.backward()\n",
        "        # optimizer 업데이트\n",
        "        optimizer.step()\n",
        "        # scheduler 업데이트\n",
        "        scheduler.step()\n",
        "\n",
        "        batch_loss += loss.item()\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        rdass_loss = metric(text = text_input_ids,label=  label_input_ids, answer = output['golden_summary'])\n",
        "        if (step%500 == 0) and (step!=0):\n",
        "            print(f\"Step: {step} Loss: {batch_loss/batch_step:.4f} lr: {optimizer.param_groups[0]['lr']:.4f}\")\n",
        "            # 변수 초기화    \n",
        "            batch_loss, batch_step = 0,0\n",
        "    \n",
        "    print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "    print(f\"*****Epoch {epoch} Train Finished*****\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw3Cv452e1y1"
      },
      "outputs": [],
      "source": [
        "def get_candidate_id(tokenizer, cls, sep_id, idx):\n",
        "\n",
        "    idx_path = join(temp_path, str(idx))\n",
        "    \n",
        "    # create some temporary files to calculate ROUGE\n",
        "    sp.call('mkdir ' + idx_path, shell=True)\n",
        "    sp.call('mkdir ' + join(idx_path, 'decode'), shell=True)\n",
        "    sp.call('mkdir ' + join(idx_path, 'reference'), shell=True)\n",
        "    \n",
        "    # load data\n",
        "    data = {}\n",
        "    data['text'] = original_data[idx]['text']\n",
        "    data['summary'] = original_data[idx]['summary']\n",
        "    \n",
        "    # write reference summary to temporary files\n",
        "    ref_dir = join(idx_path, 'reference')\n",
        "    with open(join(ref_dir, '0.ref'), 'w') as f:\n",
        "        for sentence in data['summary']:\n",
        "            print(sentence, file=f)\n",
        "\n",
        "    # get candidate summaries\n",
        "    # here is for CNN/DM: truncate each document into the 5 most important sentences (using BertExt), \n",
        "    # then select any 2 or 3 sentences to form a candidate summary, so there are C(5,2)+C(5,3)=20 candidate summaries.\n",
        "    # if you want to process other datasets, you may need to adjust these numbers according to specific situation.\n",
        "    sent_id = sent_ids[idx]['sent_id'][:5]\n",
        "    indices = list(combinations(sent_id, 2))\n",
        "    indices += list(combinations(sent_id, 3))\n",
        "    if len(sent_id) < 2:\n",
        "        indices = [sent_id]\n",
        "    \n",
        "    # get ROUGE score for each candidate summary and sort them in descending order\n",
        "    score = []\n",
        "    for i in indices:\n",
        "        i = list(i)\n",
        "        i.sort()\n",
        "        # write dec\n",
        "        dec = []\n",
        "        for j in i:\n",
        "            sent = data['text'][j]\n",
        "            dec.append(sent)\n",
        "        score.append((i, get_rouge(idx_path, dec)))\n",
        "    score.sort(key=lambda x : x[1], reverse=True)\n",
        "    \n",
        "    # write candidate indices and score\n",
        "    data['ext_idx'] = sent_id\n",
        "    data['indices'] = []\n",
        "    data['score'] = []\n",
        "    for i, R in score:\n",
        "        data['indices'].append(list(map(int, i)))\n",
        "        data['score'].append(R)\n",
        "\n",
        "    # tokenize and get candidate_id\n",
        "    candidate_summary = []\n",
        "    for i in data['indices']:\n",
        "        cur_summary = [cls]\n",
        "        for j in i:\n",
        "            cur_summary += data['text'][j].split()\n",
        "        cur_summary = cur_summary[:MAX_LEN]\n",
        "        cur_summary = ' '.join(cur_summary)\n",
        "        candidate_summary.append(cur_summary)\n",
        "    \n",
        "    data['candidate_id'] = []\n",
        "    for summary in candidate_summary:\n",
        "        token_ids = tokenizer.encode(summary, add_special_tokens=False)[:(MAX_LEN - 1)]\n",
        "        token_ids += sep_id\n",
        "        data['candidate_id'].append(token_ids)\n",
        "    \n",
        "    # tokenize and get text_id\n",
        "    text = [cls]\n",
        "    for sent in data['text']:\n",
        "        text += sent.split()\n",
        "    text = text[:MAX_LEN]\n",
        "    text = ' '.join(text)\n",
        "    token_ids = tokenizer.encode(text, add_special_tokens=False)[:(MAX_LEN - 1)]\n",
        "    token_ids += sep_id\n",
        "    data['text_id'] = token_ids\n",
        "    \n",
        "    # tokenize and get summary_id\n",
        "    summary = [cls]\n",
        "    for sent in data['summary']:\n",
        "        summary += sent.split()\n",
        "    summary = summary[:MAX_LEN]\n",
        "    summary = ' '.join(summary)\n",
        "    token_ids = tokenizer.encode(summary, add_special_tokens=False)[:(MAX_LEN - 1)]\n",
        "    token_ids += sep_id\n",
        "    data['summary_id'] = token_ids\n",
        "    \n",
        "    # write processed data to temporary file\n",
        "    processed_path = join(temp_path, 'processed')\n",
        "    with open(join(processed_path, '{}.json'.format(idx)), 'w') as f:\n",
        "        json.dump(data, f, indent=4) \n",
        "    \n",
        "    sp.call('rm -r ' + idx_path, shell=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "기업과제 4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
