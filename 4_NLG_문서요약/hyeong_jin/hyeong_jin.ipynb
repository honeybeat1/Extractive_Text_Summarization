{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "기업과제 4",
      "provenance": [],
      "collapsed_sections": [
        "h7kzv5U25HUQ",
        "XhpUnNfR63sq"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 설정 + 필요한 모델 다운로드"
      ],
      "metadata": {
        "id": "gcDvXF_FGN9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/SKT-AI/KoBART #egg=kobart"
      ],
      "metadata": {
        "id": "sXS8BohW9mHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9ae549-c4d8-44c1-97d0-8d3254050ce9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/SKT-AI/KoBART\n",
            "  Cloning https://github.com/SKT-AI/KoBART to /tmp/pip-req-build-z_zmvqi5\n",
            "  Running command git clone -q https://github.com/SKT-AI/KoBART /tmp/pip-req-build-z_zmvqi5\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.22-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from kobart==0.5.1) (1.3.5)\n",
            "Collecting pytorch-lightning==1.2.1\n",
            "  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
            "\u001b[K     |████████████████████████████████| 814 kB 36.5 MB/s \n",
            "\u001b[?25hCollecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 18 kB/s \n",
            "\u001b[?25hCollecting transformers==4.3.3\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (1.21.5)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (2.8.0)\n",
            "Collecting PyYAML!=5.4.*,>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (4.63.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 61.7 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 60.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->kobart==0.5.1) (3.10.0.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (4.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.4.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->kobart==0.5.1) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.2.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.0 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart==0.5.1) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart==0.5.1) (2.0.12)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.22\n",
            "  Downloading botocore-1.24.22-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 37.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.22->boto3->kobart==0.5.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->kobart==0.5.1) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->kobart==0.5.1) (2018.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart==0.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart==0.5.1) (1.1.0)\n",
            "Building wheels for collected packages: kobart, future\n",
            "  Building wheel for kobart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobart: filename=kobart-0.5.1-py3-none-any.whl size=9562 sha256=71e0e830b358bd24e0651268649f52767307f4e30ce8f2138c04f17824393c56\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nks8rupp/wheels/6e/55/c4/bd4fede223bc304089ac8da2a2099a69db3fcd4b0e853383f5\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=5cbb5a53000d2fe4d40efbb19eaab3b005fd6e78663b86919295f9f5abd4f120\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built kobart future\n",
            "Installing collected packages: urllib3, multidict, frozenlist, yarl, jmespath, asynctest, async-timeout, aiosignal, fsspec, botocore, aiohttp, torch, tokenizers, sacremoses, s3transfer, PyYAML, future, transformers, pytorch-lightning, boto3, kobart\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 boto3-1.21.22 botocore-1.24.22 frozenlist-1.3.0 fsspec-2022.2.0 future-0.18.2 jmespath-1.0.0 kobart-0.5.1 multidict-6.0.2 pytorch-lightning-1.2.1 s3transfer-0.5.2 sacremoses-0.0.49 tokenizers-0.10.3 torch-1.7.1 transformers-4.3.3 urllib3-1.25.11 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_oPnfM62iN",
        "outputId": "2419cf8c-a695-4f82-d3c1-c0d146befeaf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZL4Q4KFTvJ3",
        "outputId": "598ec347-41da-4d65-c8a4-69afa45df7dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (3.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KUfwH5tXtEyQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os \n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "import re\n",
        "from konlpy.tag import Okt\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from itertools import combinations\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "from transformers import AutoModel, AutoTokenizer, BartModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58DHYlQkt95N",
        "outputId": "be541334-dc7b-4efe-86da-7dbe50841ff9"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 원본 데이터 불러오기"
      ],
      "metadata": {
        "id": "h7kzv5U25HUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHXL22kYyWxV",
        "outputId": "6c5ba050-964d-4982-fa56-365643d177c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_test = pd.read_csv(\"/content/drive/MyDrive/NLP/sports_news_data - sports_news_data.csv\")"
      ],
      "metadata": {
        "id": "j7Yjhg1D1s76"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_test.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3U1QMZqj2Lcd",
        "outputId": "30c340dd-c442-4670-92e5-3643748c54de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           TITLE  \\\n",
              "0               스털링 다이빙 논란 종결?… “오른쪽 다리 접촉 있었잖아”   \n",
              "1               ‘디 마리아 없다’ 유로X코파 베스트11, 이탈리아만 7명   \n",
              "2             ‘슈퍼컴퓨터 예측’ 맨시티 우승-맨유 4위… 토트넘은 ‘6위’   \n",
              "3      “이재성, 완벽한 프로… 마인츠서 성공할 것” 킬 디렉터의 애정 듬뿍 응원   \n",
              "4   ‘홈킷과 딴판’ 바르사 팬들, NEW 어웨이 셔츠 호평… “가장 좋아하는 색!”   \n",
              "5        긴급 수혈된 바르사 NO.9, 1년 반 만에 떠난다… ‘EPL행 유력’   \n",
              "6    [김남구의 유럽통신] 황의조, 손흥민 소속사와 손잡다… CAA Base와 계약   \n",
              "7           \"메시 종신은 축복!\"…스폰서 5년 더 보장, 바르셀로나 함박웃음   \n",
              "8        [오피셜] 눈물 흘렸던 '37세 전설' 로번, 두 번째 현역 은퇴 발표   \n",
              "9           100세' 메시팬 할아버지, 748골 수기 작성…메시도 감사 인사   \n",
              "10               475억원이면 맨유 떠난다…시메오네의 픽, 부활한 린가드   \n",
              "11           토트넘, 케인 대체자 ‘세리에A 21골+810억 골잡이’ 찾았다   \n",
              "12        1,585억에 케인 불발 맨시티, 329경기 294골 킬러 영입 추진   \n",
              "13          맨유 관심 프랑스 18세 미드필더, ‘레알이나 바르사 갈 건데요’   \n",
              "14            “메시, 월드컵 4회 우승해도 마라도나 못 넘어” 전설의 주장   \n",
              "15                        모리뉴, 손흥민 전 동료에게 “동물이다”   \n",
              "16              도르트문트, 첼시의 홀란 영입 제안 거절(英 스카이스포츠)   \n",
              "17              레노버, 인터 밀란과 파트너십 강화… 유니폼 스폰서로 나서   \n",
              "18         ‘다시 돌아와!’ 웨스트햄, 임대 전설 쓰고 떠난 린가드 영입 추진   \n",
              "19       바르셀로나 충격 요구 : 그리즈만 = 사울+200억원, 사울+선수 1명   \n",
              "\n",
              "                                              CONTENT  PUBLISH_DT  \n",
              "0   [스포탈코리아] 유럽축구연맹(UEFA) 유로 2020 심판위원장 로베르토 로세티가 ...  2021-07-15  \n",
              "1   [스포탈코리아] 유로 2020과 코파 아메리카 2021로 베스트11을 만든다면 어떤...  2021-07-15  \n",
              "2   [스포탈코리아] 새 시즌이 시작하기도 전에 슈퍼컴퓨터가 예상한 순위가 나왔다.\\n\\...  2021-07-15  \n",
              "3   [스포탈코리아] 홀슈타인 킬 우베 스토버 디렉터가 이재성을 향해 응원 메시지를 띄웠...  2021-07-15  \n",
              "4   [스포탈코리아] FC 바르셀로나가 새 시즌 원정 유니폼을 공개했다. 팬들은 만족스럽...  2021-07-15  \n",
              "5   [스포탈코리아] FC 바르셀로나는 새 시즌을 앞두고 선수단 정리가 한창이다. 잉여 ...  2021-07-15  \n",
              "6   [스포탈코리아=파리(프랑스)] 황의조(지롱댕 드 보르도)가 한국 선수로는 3번째로 ...  2021-07-15  \n",
              "7   [스포탈코리아] 리오넬 메시(34)가 FC바르셀로나에 남는다. 연봉을 절반 삭감하지...  2021-07-15  \n",
              "8   [스포탈코리아] 네덜란드 축구스타 아르연 로번(37)이 현역 은퇴를 밝혔다. \\n\\...  2021-07-15  \n",
              "9   [스포탈코리아] 리오넬 메시(34)는 프로 데뷔하고 748골을 터뜨렸다. 전산화 하...  2021-07-15  \n",
              "10  [스포탈코리아] 스페인 프리메라리가 챔피언 아틀레티코 마드리드가 부활한 제시 린가드...  2021-07-15  \n",
              "11  [스포탈코리아] 토트넘 홋스퍼가 해리 케인(27) 이탈을 대비하고 있다. 이탈리아 ...  2021-07-15  \n",
              "12  [스포탈코리아] 맨체스터 시티가 확실한 킬러를 찾기 위해 분주하다. \\n\\n맨시티는...  2021-07-15  \n",
              "13  [스포탈코리아] ‘잉글랜드보다 스페인이 더 끌리네요’\\n\\n빅클럽들이 군침을 흘리고...  2021-07-15  \n",
              "14  [스포탈코리아] 리오넬 메시(34, FC바르셀로나)가 선배인 故 디에고 마라도와 또...  2021-07-15  \n",
              "15  [스포탈코리아] AS로마 수장 조세 모리뉴(58)가 손흥민(29, 토트넘 홋스퍼)의...  2021-07-15  \n",
              "16  [스포탈코리아] 보루시아 도르트문트가 뜨거운 감자 엘링 홀란(20)을 붙잡는다.\\n...  2021-07-15  \n",
              "17  [스포탈코리아] 세계 1위 PC 및 스마트 디바이스 업체 레노버가 인터 밀란과 파트...  2021-07-15  \n",
              "18  [스포탈코리아] 웨스트햄 유나이티드가 제시 린가드(맨체스터 유나이티드) 영입에 원하...  2021-07-15  \n",
              "19  [스포탈코리아] FC바르셀로나가 아틀레티코 마드리드에 트레이드를 요구했다. \\n\\n...  2021-07-15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48d68f8b-a6cf-4c8a-ac23-ddc1bdb6c2e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>PUBLISH_DT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>스털링 다이빙 논란 종결?… “오른쪽 다리 접촉 있었잖아”</td>\n",
              "      <td>[스포탈코리아] 유럽축구연맹(UEFA) 유로 2020 심판위원장 로베르토 로세티가 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‘디 마리아 없다’ 유로X코파 베스트11, 이탈리아만 7명</td>\n",
              "      <td>[스포탈코리아] 유로 2020과 코파 아메리카 2021로 베스트11을 만든다면 어떤...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‘슈퍼컴퓨터 예측’ 맨시티 우승-맨유 4위… 토트넘은 ‘6위’</td>\n",
              "      <td>[스포탈코리아] 새 시즌이 시작하기도 전에 슈퍼컴퓨터가 예상한 순위가 나왔다.\\n\\...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“이재성, 완벽한 프로… 마인츠서 성공할 것” 킬 디렉터의 애정 듬뿍 응원</td>\n",
              "      <td>[스포탈코리아] 홀슈타인 킬 우베 스토버 디렉터가 이재성을 향해 응원 메시지를 띄웠...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‘홈킷과 딴판’ 바르사 팬들, NEW 어웨이 셔츠 호평… “가장 좋아하는 색!”</td>\n",
              "      <td>[스포탈코리아] FC 바르셀로나가 새 시즌 원정 유니폼을 공개했다. 팬들은 만족스럽...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>긴급 수혈된 바르사 NO.9, 1년 반 만에 떠난다… ‘EPL행 유력’</td>\n",
              "      <td>[스포탈코리아] FC 바르셀로나는 새 시즌을 앞두고 선수단 정리가 한창이다. 잉여 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[김남구의 유럽통신] 황의조, 손흥민 소속사와 손잡다… CAA Base와 계약</td>\n",
              "      <td>[스포탈코리아=파리(프랑스)] 황의조(지롱댕 드 보르도)가 한국 선수로는 3번째로 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"메시 종신은 축복!\"…스폰서 5년 더 보장, 바르셀로나 함박웃음</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34)가 FC바르셀로나에 남는다. 연봉을 절반 삭감하지...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[오피셜] 눈물 흘렸던 '37세 전설' 로번, 두 번째 현역 은퇴 발표</td>\n",
              "      <td>[스포탈코리아] 네덜란드 축구스타 아르연 로번(37)이 현역 은퇴를 밝혔다. \\n\\...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100세' 메시팬 할아버지, 748골 수기 작성…메시도 감사 인사</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34)는 프로 데뷔하고 748골을 터뜨렸다. 전산화 하...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>475억원이면 맨유 떠난다…시메오네의 픽, 부활한 린가드</td>\n",
              "      <td>[스포탈코리아] 스페인 프리메라리가 챔피언 아틀레티코 마드리드가 부활한 제시 린가드...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>토트넘, 케인 대체자 ‘세리에A 21골+810억 골잡이’ 찾았다</td>\n",
              "      <td>[스포탈코리아] 토트넘 홋스퍼가 해리 케인(27) 이탈을 대비하고 있다. 이탈리아 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1,585억에 케인 불발 맨시티, 329경기 294골 킬러 영입 추진</td>\n",
              "      <td>[스포탈코리아] 맨체스터 시티가 확실한 킬러를 찾기 위해 분주하다. \\n\\n맨시티는...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>맨유 관심 프랑스 18세 미드필더, ‘레알이나 바르사 갈 건데요’</td>\n",
              "      <td>[스포탈코리아] ‘잉글랜드보다 스페인이 더 끌리네요’\\n\\n빅클럽들이 군침을 흘리고...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>“메시, 월드컵 4회 우승해도 마라도나 못 넘어” 전설의 주장</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34, FC바르셀로나)가 선배인 故 디에고 마라도와 또...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>모리뉴, 손흥민 전 동료에게 “동물이다”</td>\n",
              "      <td>[스포탈코리아] AS로마 수장 조세 모리뉴(58)가 손흥민(29, 토트넘 홋스퍼)의...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>도르트문트, 첼시의 홀란 영입 제안 거절(英 스카이스포츠)</td>\n",
              "      <td>[스포탈코리아] 보루시아 도르트문트가 뜨거운 감자 엘링 홀란(20)을 붙잡는다.\\n...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>레노버, 인터 밀란과 파트너십 강화… 유니폼 스폰서로 나서</td>\n",
              "      <td>[스포탈코리아] 세계 1위 PC 및 스마트 디바이스 업체 레노버가 인터 밀란과 파트...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>‘다시 돌아와!’ 웨스트햄, 임대 전설 쓰고 떠난 린가드 영입 추진</td>\n",
              "      <td>[스포탈코리아] 웨스트햄 유나이티드가 제시 린가드(맨체스터 유나이티드) 영입에 원하...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>바르셀로나 충격 요구 : 그리즈만 = 사울+200억원, 사울+선수 1명</td>\n",
              "      <td>[스포탈코리아] FC바르셀로나가 아틀레티코 마드리드에 트레이드를 요구했다. \\n\\n...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48d68f8b-a6cf-4c8a-ac23-ddc1bdb6c2e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48d68f8b-a6cf-4c8a-ac23-ddc1bdb6c2e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48d68f8b-a6cf-4c8a-ac23-ddc1bdb6c2e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리\n",
        "- 중복 및 결측치 제거\n",
        "- 크롤링 상에서 생긴 쓸모 없는 문구 처리\n"
      ],
      "metadata": {
        "id": "XhpUnNfR63sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(string):\n",
        "    str_list = string.split('\\n\\n') # \\n\\n 기준으로 분리\n",
        "    str_list[0] = str_list[0].replace('[스포탈코리아] ', '') # [스포탈코리아] 삭제\n",
        "    \n",
        "    result = []\n",
        "    for strg in str_list:\n",
        "        strg = re.sub(r'\\([^)]*\\)|\\[[^)]*\\]|\\<[^)]*\\>', ' ', strg) # 괄호와 그 안에 문자 제거\n",
        "\n",
        "        if '기자' in strg: # 기자 이름이 들어간 경우 기자이름 삭제\n",
        "            strg = strg.split('기자')[-1]\n",
        "        if '다.' in strg: # 문장 단위로 분리\n",
        "            strg = strg.split('. ')\n",
        "            for s in strg:\n",
        "                if s != '':\n",
        "                    result.append(s)\n",
        "            \n",
        "    return result"
      ],
      "metadata": {
        "id": "QgS0iTJ8QT0F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def special(str_list):\n",
        "    regex = r\"[^가-힣a-zA-Z0-9 ]\" # 특수 문자 제거\n",
        "    for i in range(len(str_list)):\n",
        "        str_list[i] = re.sub(regex, '', str_list[i])\n",
        "\n",
        "    return str_list"
      ],
      "metadata": {
        "id": "uMpyTPRiQwWb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def special_title(string):\n",
        "    regex = r\"[^가-힣a-zA-Z0-9 ]\" # 특수 문자 제거\n",
        "    string = re.sub(regex, '', string)\n",
        "\n",
        "    return string"
      ],
      "metadata": {
        "id": "MQSj-oMeQ5Yb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_data=csv_test.dropna().copy()\n",
        "  \n",
        "idx = trimmed_data['CONTENT'].drop_duplicates().index\n",
        "trimmed_data = trimmed_data.loc[idx]\n",
        "\n",
        "idx = trimmed_data['TITLE'].drop_duplicates().index\n",
        "trimmed_data = trimmed_data.loc[idx]\n",
        "\n",
        "trimmed_data['CONTENT'] = trimmed_data['CONTENT'].apply(preprocess)\n",
        "trimmed_data['CONTENT'] = trimmed_data['CONTENT'].apply(special)\n",
        "trimmed_data['TITLE'] = trimmed_data['TITLE'].apply(special_title)\n"
      ],
      "metadata": {
        "id": "SA9s6Ts52cYZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trimmed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWzYDTh748dO",
        "outputId": "8b63bcea-0ab5-4ee1-b198-35a5f907c952"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8995"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_data['CONTENT'].iloc[8991]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY0DpSOn95HL",
        "outputId": "63171bd2-58c3-4d1b-99fb-c4b4b62bad4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['성남FC가 만17세 2004년생 수비수 김지수와 준프로 계약을 체결했다',\n",
              " '김지수는 192cm84kg의 체격에 제공권이 좋고 시야가 넓어 대인 방어와 패스에 능하다',\n",
              " ' 김지수는 성남FC U15 U18에서 활약하며 성남의 유망주로 이름을 알렸으며 꾸준히 연령별 대표팀에도 이름을 올리고 있다',\n",
              " 'U15 크로아티아 국제 축구대회와 AFC U16 챔피언십 예선 참여 2021년 경기도 꿈나무 축구대회 우승 2021년 제29회 백록기 전국 고교 축구대회에서 우승 주역으로 베스트 영플레이어상을 수상한 김지수는 성남FC U18 풍생고에서 성장 가능성이 큰 선수로 꼽혀왔다 구단은 유소년 육성에 집중 투자하면서 구단 유스 프로 계약의 증가와 구단 최초 준프로 계약 등 점차 가시적인 성과를 내고 있으며 꾸준한 유소년 시스템 투자와 유망주 발굴을 통해 구단의 지속적 성장의 기틀을 다질 예정이다 김남일 감독은 풍생고 경기를 꾸준히 보면서 김지수를 눈여겨봤었다',\n",
              " '책임감 있고 안정적인 경기 운영을 하는 것이 눈에 띄었다',\n",
              " '김지수가 성남에서 첫 프로 도전을 하는 만큼 열심히 준비해서 경기장에서 본인의 잠재력을 마음껏 펼치길 바란다라고 밝혔다 김지수는 이번 1차 전지훈련에서 프로팀 형들과 훈련을 한 것도 영광이었는데 바로 계약까지 하게 된 게 아직 꿈만 같다',\n",
              " '성남 유스 출신 선수라는 책임감이 생겼다',\n",
              " '2차 전지훈련 동안 선수 형들에게 많이 배우고 열심히 준비해서 팀에 도움이 되고 싶다라고 밝혔다 그는 성남FC 협력병원인 분당베스트병원에서 메디컬테스트를 마쳤고 2차 전지훈련지인 부산 기장으로 출발하여 본격적인 2022시즌 준비에 나선다']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 띄어쓰기 및 불용어 처리"
      ],
      "metadata": {
        "id": "ZOrftvJW63Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 불용어 리스트 크롤링\n",
        "\n",
        "\n",
        "url = \"https://www.ranks.nl/stopwords/korean\"\n",
        "response = requests.get(url, verify = False)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    content = soup.select_one('#article178ebefbfb1b165454ec9f168f545239 > div.panel-body > table > tbody > tr')\n",
        "    stop_words=[]\n",
        "    for x in content.strings:\n",
        "        x=x.strip()\n",
        "        if x:\n",
        "            stop_words.append(x)\n",
        "    print(f\"# Korean stop words: {len(stop_words)}\")\n",
        "else:\n",
        "    print(response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sNfaAWH6fTI",
        "outputId": "800445df-3120-43c2-f1b5-0086fb40a538"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ranks.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Korean stop words: 677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "okt = Okt()\n",
        "for i in tqdm(range(len(trimmed_data))):\n",
        "  temp_data = okt.morphs(trimmed_data[\"TITLE\"].iloc[i])\n",
        "  temp_list = []\n",
        "\n",
        "  for word in temp_data:\n",
        "    if word in stop_words: continue\n",
        "    temp_list.append(word)\n",
        "  \n",
        "  trimmed_data[\"TITLE\"].iloc[i] = \" \".join(temp_list)\n",
        "\n",
        "  temp_list = []\n",
        "  for sentence in trimmed_data[\"CONTENT\"].iloc[i]:\n",
        "    temp_data = okt.morphs(sentence)\n",
        "    temp_sentecne_list = []\n",
        "    \n",
        "    for word in temp_data:\n",
        "      if word in stop_words: continue\n",
        "      temp_sentecne_list.append(word)\n",
        "    \n",
        "    temp_sentence = \" \".join(temp_sentecne_list)\n",
        "    temp_list.append(temp_sentence)\n",
        "  \n",
        "  trimmed_data[\"CONTENT\"].iloc[i] = temp_list\n",
        "  \n"
      ],
      "metadata": {
        "id": "0lCXhA4D_WBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3873095-2bb8-4964-eda2-e342006631f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8995/8995 [05:04<00:00, 29.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7Mg_VIivfdpZ",
        "outputId": "6a728301-5f53-4baa-cb16-aeef5b47abfe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 TITLE  \\\n",
              "0         스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아   \n",
              "1   디 마리아 없다 유로 X 코파 베스트 11 이탈리아 만 7 명   \n",
              "2     슈퍼컴퓨터 예측 맨시티 우승 맨유 4 위 토트넘 은 6 위   \n",
              "3  이재성 완벽한 프로 마인츠 서 성공할 킬 디렉터 애정 듬뿍 응원   \n",
              "4   홈킷 딴판 바르사 팬 NEW 웨이 셔츠 호평 가장 좋아하는 색   \n",
              "\n",
              "                                             CONTENT  PUBLISH_DT  \n",
              "0  [유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나...  2021-07-15  \n",
              "1  [지난달 시작 된 유로 코파 아메리카 11일 끝 막 내렸다, 이탈리아 는 결승전 잉...  2021-07-15  \n",
              "2  [새 시즌 시작 하기도 전 슈퍼컴퓨터 예상 한 순위 나왔다, 영국 매체 스포츠 바이...  2021-07-15  \n",
              "3  [홀슈타인 킬 우베 스토 버 디렉터 이재성 향 해 응원 메시지 띄웠다, 이재성 은 ...  2021-07-15  \n",
              "4  [FC 바르셀로나 새 시즌 원정 유니폼 공개 했다, 팬 은 만족스럽다는 반응 이다,...  2021-07-15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0067fda-7810-4387-9b33-759e878ac848\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>PUBLISH_DT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아</td>\n",
              "      <td>[유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>디 마리아 없다 유로 X 코파 베스트 11 이탈리아 만 7 명</td>\n",
              "      <td>[지난달 시작 된 유로 코파 아메리카 11일 끝 막 내렸다, 이탈리아 는 결승전 잉...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>슈퍼컴퓨터 예측 맨시티 우승 맨유 4 위 토트넘 은 6 위</td>\n",
              "      <td>[새 시즌 시작 하기도 전 슈퍼컴퓨터 예상 한 순위 나왔다, 영국 매체 스포츠 바이...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이재성 완벽한 프로 마인츠 서 성공할 킬 디렉터 애정 듬뿍 응원</td>\n",
              "      <td>[홀슈타인 킬 우베 스토 버 디렉터 이재성 향 해 응원 메시지 띄웠다, 이재성 은 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>홈킷 딴판 바르사 팬 NEW 웨이 셔츠 호평 가장 좋아하는 색</td>\n",
              "      <td>[FC 바르셀로나 새 시즌 원정 유니폼 공개 했다, 팬 은 만족스럽다는 반응 이다,...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0067fda-7810-4387-9b33-759e878ac848')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0067fda-7810-4387-9b33-759e878ac848 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0067fda-7810-4387-9b33-759e878ac848');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_row = trimmed_data.iloc[0]\n",
        "print(data_row)\n",
        "\n",
        "text = data_row['CONTENT']\n",
        "print(text)\n",
        "\n",
        "for i, sentence in enumerate(text):\n",
        "  print(i)\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no71C-gm-b3r",
        "outputId": "4d6aace1-5286-49c9-dfb3-283565556fb3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TITLE                              스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아\n",
            "CONTENT       [유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나...\n",
            "PUBLISH_DT                                           2021-07-15\n",
            "Name: 0, dtype: object\n",
            "['유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나온 판정 논란 정심 이라고 공언 했다', '지난 8일 잉글랜드 덴마크 는 유로 2020 4 강 결승 티켓 두고 격돌 했다', '연장 접전 끝 잉글랜드 21 이겼다', '경기 후 논란 불거졌다', '11 팽팽 하던 연장 전반 12분 라 힘 스털링 드리블 돌파 하던 중 요아킴 멜레 마티아스 옌센 사이 넘어졌다', '심판 은 곧장 페널티 스팟 찍었다', '비디오 판독 실과 의견 나눈 뒤 에도 원심 유지 했다', '페널티킥 얻은 잉글랜드 는 해리 케인 실축 했지만 흐른 볼 밀어 넣어 결승 티켓 따냈다', '장면 두고 갑론 박 펼쳐졌다', '스털링 은 경기 후 인터뷰 명백한 페널티킥 이라고 주장 했지만 전문가 의견 은 달랐다', '조제 모리뉴 AS 로마 감독 아르 센 벵거 전 아스널 감독 은 페널티킥 아니다고 입 모았다', '많은 이야기 흘러나오는 가운데 유로 2020 심판 위원장 로세티 오심 아니라는 입장 내놨다', '로세티 위원장 은 14일 영국 매체 가디언 인터뷰 주심 은 5 번 수비수 주목 했다', '수비수 볼 터치 하지 않았다고 봤다', '멜레 오른쪽 다리 스털링 오른쪽 다리 접촉 한 확인 했다', '접촉 강도 논 할 수 있지만 는 항상 심판 의사결정 과정 중심 되길 바란다고 밝혔다', '로세티 위원장 심판 대표 해 의견 냈지만 오심 이라고 생각 하는 받아들일지는 미지수 다', '스털링 은 평소 에도 다이빙 논란 시 달려왔고 많은 머릿속 다이버 라는 인식 가득하기 때문 이다']\n",
            "0\n",
            "유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나온 판정 논란 정심 이라고 공언 했다\n",
            "1\n",
            "지난 8일 잉글랜드 덴마크 는 유로 2020 4 강 결승 티켓 두고 격돌 했다\n",
            "2\n",
            "연장 접전 끝 잉글랜드 21 이겼다\n",
            "3\n",
            "경기 후 논란 불거졌다\n",
            "4\n",
            "11 팽팽 하던 연장 전반 12분 라 힘 스털링 드리블 돌파 하던 중 요아킴 멜레 마티아스 옌센 사이 넘어졌다\n",
            "5\n",
            "심판 은 곧장 페널티 스팟 찍었다\n",
            "6\n",
            "비디오 판독 실과 의견 나눈 뒤 에도 원심 유지 했다\n",
            "7\n",
            "페널티킥 얻은 잉글랜드 는 해리 케인 실축 했지만 흐른 볼 밀어 넣어 결승 티켓 따냈다\n",
            "8\n",
            "장면 두고 갑론 박 펼쳐졌다\n",
            "9\n",
            "스털링 은 경기 후 인터뷰 명백한 페널티킥 이라고 주장 했지만 전문가 의견 은 달랐다\n",
            "10\n",
            "조제 모리뉴 AS 로마 감독 아르 센 벵거 전 아스널 감독 은 페널티킥 아니다고 입 모았다\n",
            "11\n",
            "많은 이야기 흘러나오는 가운데 유로 2020 심판 위원장 로세티 오심 아니라는 입장 내놨다\n",
            "12\n",
            "로세티 위원장 은 14일 영국 매체 가디언 인터뷰 주심 은 5 번 수비수 주목 했다\n",
            "13\n",
            "수비수 볼 터치 하지 않았다고 봤다\n",
            "14\n",
            "멜레 오른쪽 다리 스털링 오른쪽 다리 접촉 한 확인 했다\n",
            "15\n",
            "접촉 강도 논 할 수 있지만 는 항상 심판 의사결정 과정 중심 되길 바란다고 밝혔다\n",
            "16\n",
            "로세티 위원장 심판 대표 해 의견 냈지만 오심 이라고 생각 하는 받아들일지는 미지수 다\n",
            "17\n",
            "스털링 은 평소 에도 다이빙 논란 시 달려왔고 많은 머릿속 다이버 라는 인식 가득하기 때문 이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sentence_num = 0\n",
        "for i in range(len(trimmed_data)):\n",
        "  sentence_num = len(trimmed_data[\"CONTENT\"].iloc[i])\n",
        "  max_sentence_num = max(sentence_num,max_sentence_num)\n",
        "\n",
        "print(max_sentence_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa_-ie2sN7Gg",
        "outputId": "fc351b38-e80b-43c6-a2ad-a850ee1d474f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extractive summarization - Matchsum"
      ],
      "metadata": {
        "id": "OwR_0Y2Uyc0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset & Dataloader 생성"
      ],
      "metadata": {
        "id": "7NQTQNZdTDuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def control_input_ids(input_ids_tensor,length,cls_token_num,sep_token_num,pad_token_num):\n",
        "  cur_length = len(input_ids_tensor)\n",
        "  cls_token = torch.tensor([cls_token_num])\n",
        "  sep_token = torch.tensor([sep_token_num])\n",
        "\n",
        "  if cur_length+2 > length:\n",
        "    input_ids_tensor = input_ids_tensor[:length-2]  # 길이가 넘치면 자른다\n",
        "    return torch.cat([cls_token,input_ids_tensor,sep_token])\n",
        "  else:\n",
        "    input_ids_tensor = torch.cat([cls_token,input_ids_tensor,sep_token])\n",
        "    padding_list = torch.tensor([pad_token_num]*(length - cur_length -2)) # 길이가 모자라면 padding token 을 채운다\n",
        "    return torch.cat([input_ids_tensor,padding_list])"
      ],
      "metadata": {
        "id": "YBy1iVi6PfKj"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(samples):\n",
        "  \n",
        "  text_ids = torch.empty(0,512)\n",
        "  labels_ids = torch.empty(0,32)\n",
        "  for sample in samples:\n",
        "    text_ids = torch.cat([text_ids,sample['text_input_ids'].unsqueeze(0)],dim=0) \n",
        "    labels_ids = torch.cat([labels_ids,sample['labels_input_ids'].unsqueeze(0)],dim=0)\n",
        "\n",
        "  sentence_input_ids = [sample['sentence_input_ids'] for sample in samples]\n",
        "  nn.utils.rnn.pad_sequence(sentence_input_ids,batch_first=True,padding_value = 1)\n",
        "\n",
        "  return dict(text_input_ids = text_ids.to(torch.int64), labels_input_ids = labels_ids.to(torch.int64), sentence_input_ids = sentence_input_ids)"
      ],
      "metadata": {
        "id": "bUCSPhOid36D"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(\n",
        "      self, data, tokenizer,\n",
        "      text_max_token_len = 512,\n",
        "      summary_max_token_len = 32\n",
        "        ):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.text_max_token_len = text_max_token_len\n",
        "    self.summary_max_token_len = summary_max_token_len\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    cls_token_num = 0\n",
        "    sep_token_num = 2\n",
        "    pad_token_num = 1\n",
        "    \n",
        "    data_row = self.data.iloc[index]\n",
        "    text = data_row['CONTENT']\n",
        "    \n",
        "    total_text_ids = torch.tensor([])\n",
        "    sentence_input_ids = torch.empty(0,32)\n",
        "\n",
        "    for sentence in text:\n",
        "      text_encoding_sentence = self.tokenizer(\n",
        "          sentence,return_tensors = \"pt\",add_special_tokens=False)\n",
        "      sentence_indiv_input_ids = text_encoding_sentence['input_ids'].flatten()\n",
        "      total_text_ids = torch.cat([total_text_ids,sentence_indiv_input_ids])\n",
        "\n",
        "      sentence_indiv_input_ids = control_input_ids(sentence_indiv_input_ids,self.summary_max_token_len,cls_token_num,sep_token_num,pad_token_num)\n",
        "      sentence_indiv_input_ids = sentence_indiv_input_ids.unsqueeze(0)\n",
        "      sentence_input_ids = torch.cat([sentence_input_ids,sentence_indiv_input_ids],dim=0)\n",
        "    \n",
        "    sentence_input_ids = sentence_input_ids.to(torch.int64)\n",
        "    total_text_ids = control_input_ids(total_text_ids,self.text_max_token_len,cls_token_num,sep_token_num,pad_token_num)    \n",
        "    total_text_ids = total_text_ids\n",
        "\n",
        "    labels = data_row['TITLE']\n",
        "    summary_encoding = self.tokenizer(\n",
        "        labels,\n",
        "        add_special_tokens = False,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "\n",
        "    labels_ids = summary_encoding['input_ids'].flatten()\n",
        "    labels_ids = control_input_ids(labels_ids,self.summary_max_token_len,cls_token_num,sep_token_num,pad_token_num)\n",
        "\n",
        "    return dict(text_input_ids = total_text_ids, labels_input_ids = labels_ids, sentence_input_ids = sentence_input_ids)\n"
      ],
      "metadata": {
        "id": "V93s8-DRniiR"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_kobart_tokenizer()"
      ],
      "metadata": {
        "id": "yNA-2QR7uXMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618d8f60-0901-4402-f5f8-6ac8170d4161"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.cache/kobart_base_tokenizer_cased_cf74400bce.zip[██████████████████████████████████████████████████]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whole_dataset = CustomDataset(trimmed_data,tokenizer)\n",
        "\n",
        "train_set_num = 7000\n",
        "train_dataset , valid_dataset = random_split(whole_dataset, [train_set_num,len(trimmed_data)-train_set_num])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 4, shuffle=True,collate_fn = custom_collate_fn)\n",
        "valid_dataloader =  DataLoader(valid_dataset, batch_size = 4, shuffle=False,collate_fn = custom_collate_fn)"
      ],
      "metadata": {
        "id": "hK1C6_KKrL7v"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "DguMSgTHMdT0"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbXvULnJV3fB",
        "outputId": "df554c9f-4f2b-41e0-e495-d13fe6c309f6"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text_input_ids': tensor([[    0,  6248,  3661,  ...,     1,     1,     1],\n",
            "        [    0,  8475,  4713,  ...,     1,     1,     1],\n",
            "        [    0,  7992, 12731,  ...,     1,     1,     1],\n",
            "        [    0, 20482,     3,  ...,     1,     1,     1]]), 'labels_input_ids': tensor([[    0, 11251,  1497,  3665,  3841,  3825, 18206, 18345,  3882,  5527,\n",
            "          1897, 27553,  4327,  6248, 21443, 14643,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  5136,  1513,  2088, 17134,   793,  1415,  2203,  1929,  2241,\n",
            "          4025,  3841,  3825, 27366,    23,   793,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 15246,  4159,  1122,  2886,  2062,  6261, 18181,  6951, 29288,\n",
            "          2170,  2200,  8852,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 11251, 28832,  3760,  1327,  2336, 20482,  6691,   793, 10268,\n",
            "         15855,  2111, 15051,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1]]), 'sentence_input_ids': [tensor([[    0,  6248,  3661,  1889,  2259,  4713,  3787,  1436,  2414,  1823,\n",
            "          5157,  2556, 11251,  1904,  1897, 12509,  1651,  1902,  2062,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  4232,  2210,   598, 11745,  3881,  2460,  3738, 13516, 13788,\n",
            "         22021,  9101,  3841,  4559,  8254,  9472,  1570,  2179,  5157,  2556,\n",
            "          1497,  3665,  4713,   593, 11251,  1497,  1110,  2069,  1295,  1415,\n",
            "          2259,     2],\n",
            "        [    0,  3665,  3841,  1570,  1891,  1076, 30651,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,   793,  3841,  3841,  3825,  2062,  2181,  2307, 14643,  7619,\n",
            "          2118,  1380,  2886,  2062,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  3796, 11251,  1497,   848,  3662,  2205,  4000,  6216,  1902,\n",
            "          2062,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,   720, 11251, 16915,  2470,  1839, 30651,  3609,  5074,  2062,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  5157,  2556,  1497,  1474, 19292, 11251,  5339, 11251,  3781,\n",
            "          4530,  1335,  2062,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  6248,   950,  3904,  1892,   793,  3614,  2062,  2181,  2307,\n",
            "         13338,  9112,  1506,  6300,  1943,  7849, 22430,  3604,  2079, 18206,\n",
            "         18345,  3882,  5527,  1902,  2062,     2,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  5157,  2556,  1497,  4222,  6248,  5122,  1902,  2414,  4283,\n",
            "          1924, 13806,  4327,  3825,  2507,  2062,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  6248,  3728,  5718,    37,  7752, 12309,  3682,  4718,  3956,\n",
            "           598,   751,  2359,  2062,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  5764,  2440,  4708,  2440,    28,  2440,   545, 11237, 12416,\n",
            "         17665, 12446,  2322, 10358, 13806,  5943,  1902,  2062,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  6248,   732,  3604,  2259, 10430,   555,  2073,  3990,   809,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  5157,  2556, 11251,  1497,  3728,  5718,   864,  4356, 12949,\n",
            "          2073, 25181,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1497,  4912,  2440,  6248,  8241,  3211,  1552,  1156,  4469,\n",
            "          6533,  4084,  3904,  1902,  2062,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  3629,  1497,  1552,  1156,  4469,  6248,  3633,  4644,  5245,\n",
            "          6533,  3604,  2259,  3710,  1837,  1889,  2307, 20582,  1902,  2062,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 11251,  1497,  6533,   637,  2125,  1506,  3718, 12134,  2501,\n",
            "          5639, 23893,   706,   594,   552,  2062,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1]]), tensor([[    0,  8475,  4713,  6281,  7838,  2259,  1424,  2557,  1929,  2241,\n",
            "          1163,  3738,  3665,  3841,  3825,   793,    23,  1076, 30651,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1929,  2241,  1497,  4030,  4358, 12971,  4073,   642, 11420,\n",
            "          4592,  2205,  2318,  3798,  2077,   648,  1902,  2062,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  3625,  1269,  4161, 25410,  2265, 30280,  7593,  3682,  4684,\n",
            "           598, 12939, 31369,  4960,  4392,   594,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1652,  3659, 20791,  3985,  4758, 31369,  1929,  2241,  1919,\n",
            "          5184,  3841,  3609,  1160,  2259,  5259,   848,  3732,   794,  2359,\n",
            "          2062,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,   555,  2073,  3777, 12971,  1929,  2241,  1497,  3632, 19456,\n",
            "          3825,    23,  1076,  4025,  1902,  2062,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 10500, 30000, 17482,  2440,  3841,  3825, 21627,  4676,   793,\n",
            "          4341,  1929,  2241,  1497,  4445,  3806,   991, 11842,  1812,   974,\n",
            "          5315, 19047,    21,  7587,   680,  2886,  2062,     2,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  6854,   974,  5315, 19047,   793,   555,  2073,  4407,  1175,\n",
            "         11106,  2059,  2116,   927,  2307,  6300,  3855,  1902, 12551,  3940,\n",
            "          4089,  1892,  1295,  4044,  1415,  2062,     2,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,   974,  5315, 19047,   793,  3736,  6294,  7089,   598, 12060,\n",
            "          2088,  1175, 11106,  2059,  2116,  3604,  2119,  5594,   598,  2200,\n",
            "          1891,  1897,  1670,   809,  6300,   858,  2062,     2,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  8345,  4875,    22,  2440,  4788,  3854,  4713,  6990,   831,\n",
            "          7351,  3753,  3825,  1242,  4812,  2371,  2062,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1929,  2241,  1497,  3796,  1697,  2323,  1150,  2021,  2057,\n",
            "           848,  1513,  2088, 14628,  2829,  5136,   848,  5825,  2371,  2062,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1150,  2021,  2057,    22,  1485,  5136,    23,  1485,  3609,\n",
            "          5074,  2062,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1150,  2021,  2057,   793,  4161,  5442,  4232,   598,   751,\n",
            "          2051, 15694,  5943, 28361,   594,  1513,  2088,  5136,   793,    27,\n",
            "          1141,  3135,  1123,  2498, 14433,  4812,  2097, 10452,  3806, 14703,\n",
            "          1242,     2],\n",
            "        [    0,  1388,  5050,  8015,  1892,  1295,  1513,  2259,  1929,  2241,\n",
            "          1497,  3753,  3721,   572,  5144,  5044,  1295,  1513,  4683,  3628,\n",
            "          3605,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  3794,   982,  9517,   831,  9400,  2118,  2259,  4076,  1892,\n",
            "          1295,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  5223,  1415, 13091,  3605,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,   952,  2275,   831,  1039,  2073,  3682,   927,  2307,  3859,\n",
            "          1892,  1295,  1513,  2062,  7245,  1902,  2062,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  8863,  2318,  2119,  1929,  2241,  1497,  3744,  5223,  4376,\n",
            "         25327,  3605,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  4585,  1092,  2155,  1521,  3750,  6159,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  4484,   848,  6159,  1513,  2051, 11628,  5763,  2088,   819,\n",
            "          1902,  2062,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1]]), tensor([[    0,  7992, 12731, 10093,  1891, 13078,  1969, 29288,  2170,  2200,\n",
            "         15823,  1536,  1506,  6261,  3635,  4052,  1889,  2015,  3627, 15246,\n",
            "          4159,  1122,  2886,  2062,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  6385,  5775,  1697,  2147,   717,  2103,  2131,   793, 29288,\n",
            "          2170,  2200,   991, 11842,  1812,  1285,  2189,  2131,  5155,  6261,\n",
            "         15246,  4159,  1122,  2886,  4683,  1537,  1902,  2062,     2,     1,\n",
            "             1,     1],\n",
            "        [    0,  4585,  2015,   545,  5542,  3677,  2205,  2118,  1380,  2227,\n",
            "          4294, 17802, 15962,  1869,  3042, 13300,   942,  2683,  2181,  5906,\n",
            "          3113,  1462,  2147,  4731,   878,  1122,  2886,  2414,  4757,  2062,\n",
            "             2,     1],\n",
            "        [    0, 29288,  2170,  2200,   793,  3625,  4161, 15185,  6088,  1258,\n",
            "          6261,  4775,  1122,  2886,  3683, 12193,   859,  2118,  1380,  2886,\n",
            "          2062,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  3736,  1141, 30553,  6261,  5223,  1511,  2359,  2414, 29288,\n",
            "          2170,  2200,   793,  3681,  4927,  2097,  4161,  6826,  4419,  3645,\n",
            "          1902,  2062,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  4775,  2104,  4696,   793,  5185,  2318,  6236,  1892,  1295,\n",
            "          1513,  2359,  3683,  5378,  3682,   982,  4585,  2205,  2118,  1085,\n",
            "          1902,  2062,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 29288,  2170,  2200,   793,  6261,  4021,  3627, 15246,  4159,\n",
            "           780,  8803,  2062,     2,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1697,  2147,   717,  2103,  2131,   793,  4001,  6951,  4159,\n",
            "          5158,  6095,  4338,  1891, 23034,  3644, 18181,  6951,  3662,  2205,\n",
            "          4000,   572,  6850,  1902,  2062,     2,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 29288,  2170,  2200,   848, 18181,  6951,  3825,  3799,  5219,\n",
            "          3627, 15246,  4159, 13456,  2062,   594,  3788,  1902,  2062,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 29288,  2170,  2200,  8869,  8634,  1083, 12731,  1656,  4161,\n",
            "          4209,  2318,   858,  2062,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 29288,  2170,  2200,   793,  1052, 16270,  1258,  3633,  2440,\n",
            "          3799,  6159, 12731, 13510, 10047,  2062,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 17785,  1891, 14628,  2829,  5136,   927,  2370,  2259,  5289,\n",
            "          6916,  9286,  1889,  2307, 10093, 13456,  2062,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  5136, 17482,  1726,  2160,  9583,  4564, 12297, 29288,  2170,\n",
            "          2200,   793,  8474,    22,  2210, 12731,  1823,  4484,  7468,  3605,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1]]), tensor([[    0, 20482,     3, 10371, 11251,  1523,  2073,  1327,   720,  4616,\n",
            "         30651,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  8758, 14789,  5748, 10268, 11251,  4983,  1640,  2062,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 20482,  1497,  4136,  2210,  4548,  5299,  3644, 11251,    24,\n",
            "          2440, 28832,  1057,  2359,  1500,  3913,  1902,  2062,     2,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 10093,  1415,  2259,  1891, 11251,  1497, 18994,  2440,  1316,\n",
            "          7525,  2763,   723,  2259,  2062,     2,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1823,   732,  4325,  3825,  7305,  2073,  3760,  9221,  2112,\n",
            "          4846,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 20482,  6691, 11251, 16552,  2359,  2062,     2,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  4136,  2210, 28832,  5234,  2259,  7952,  1093,  3719,  4056,\n",
            "          2210, 17252,  1668,  3876,   558,  7952,  1093,  5649, 13964, 11251,\n",
            "           606,  1891,  3800, 30651,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 28832,  5111,  4729, 17482,  5267, 14694,  2067,  1578,  7446,\n",
            "         11300,  1511,  2088,  1513,  2259,  4035,  7952,  1093,  2052, 24653,\n",
            "          2062,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  3676,  3744,  7952,  1093,  7963,  3699,   793,  1354,  2209,\n",
            "          2522,  3700,   860, 13163, 10770,  2810, 23548,   771, 12391,  7757,\n",
            "           848,  1513,  2359,  2062,     2,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 27053,  2256,  3948,  6354,   848, 10268, 11251, 30651,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 17252,  3872,  3801,  8964,  1537,  1656,  7952,  1093,  2052,\n",
            "         13289,  3670, 11251,  3700,  6354,  1038,    28,   558,  4140,  1902,\n",
            "          2062,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 20482,  7398,  3604,  2259,   645,  3216, 26752,  1889,  2062,\n",
            "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  1823,   732,  3841,  3825,  1506, 14113, 17721, 15185,  6088,\n",
            "          1430,  1504,  2088,  1513,  2259,  3850, 11251,  1523,  2886,  2015,\n",
            "          3624, 30651,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 11251,  1497,  7330,  5267, 21289,  2067,  1578, 20482, 10371,\n",
            "          1436,  2062,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 11237, 12416, 17665,  5319,  3682,  5419,  1897,  3932,   598,\n",
            "          3633,  4144,  5240,  6300,  4144,    24,  1485,  4990,  2062,     2,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 20482, 11251,  5219,  4123,  4735,  1889,  2259,  1497,  4685,\n",
            "          2470,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0,  4912,  2440,  4565, 20482, 11300,  1511,  2073, 11251,  1497,\n",
            "          3633,  2440,  9217,  4680,  1902,  2062,     2,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1],\n",
            "        [    0, 11251,  1497,    24,  2440, 28832,  1943,  6055,  4548,  5748,\n",
            "          1316, 18647,  9578,  3644, 28832,  1892,  1295,  1513,  2359,  2414,\n",
            "          1751,  3782,   793,  7254,  6504,  1897,  1564,  2250,  1839,  1175,\n",
            "          2031,     2],\n",
            "        [    0,  3732,  4245,  2205,  3683,   831,  5021,  3973,  1889,  2259,\n",
            "          3825,  7690, 20482,  4644,  1889,  2259,  3781,  4564,  2205,  2259,\n",
            "          3781,   677,  3897,  2223,  2088,  1335,  2062,  2307,  8669,  3705,\n",
            "          2062,     2]])]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output['text_input_ids'].dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvAl4467Juyq",
        "outputId": "9d530bdb-3382-4fdd-f791-6427f3da6bae"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matchsum\n",
        "\n",
        "- 평가 metric -> rdass\n",
        "- 기본적으로 모델에 스코어가 높은 5개의 단일 문장을 뽑고 뽑인 문장으로 만들어진 조합 가운데서 스코어가 높은 조합을 golden summary로 선정\n",
        "- loss 는 margin ranking loss 사용\n"
      ],
      "metadata": {
        "id": "2z5e_W-U93BH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(doc,label,answer):\n",
        "  score_1 = torch.cosine_similarity(doc,answer,dim=0)\n",
        "  score_2 = torch.cosine_similarity(label,answer,dim=0)\n",
        "  return score_1+score_2"
      ],
      "metadata": {
        "id": "2uoHyFZ8xJ6X"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_candidate_id(doc_emb,summary_emb,batch_sentence_id, candidate_num, extract_model):\n",
        "    cls_token = torch.tensor([0])\n",
        "    sep_token = torch.tensor([1])\n",
        "    candidate_ids = []\n",
        "    for batch_idx, sentence_id_list in enumerate(batch_sentence_id):\n",
        "      out = extract_model(sentence_id_list)  #sentence_id_list = [문장 갯수,32개의 토큰]\n",
        "      hidden_states = out['last_hidden_state'][:,0,:] # [문장 갯수,token 갯수 ,768 dim_vec]\n",
        "      score_list= []\n",
        "      for i in range(out.shape[0]):\n",
        "        score = get_score(doc = doc_emb[batch_idx,:], label = summary_emb[batch_idx,:], answer = out[i,:])\n",
        "        score_list.append((score,i))\n",
        "      \n",
        "      score_list.sort(key = lambda x: x[0],reverse=True)\n",
        "      idx_list = [idx for _,idx in score_list][:5]\n",
        "    \n",
        "      # get candidate summaries\n",
        "      # here is for CNN/DM: truncate each document into the 5 most important sentences (using BertExt), \n",
        "      # then select any 2 or 3 sentences to form a candidate summary, so there are C(5,2)+C(5,3)=20 candidate summaries.\n",
        "      # if you want to process other datasets, you may need to adjust these numbers according to specific situation.\n",
        "      indices = list(combinations(idx_list, 2))\n",
        "      indices += list(combinations(idx_list, 3))\n",
        "      if len(idx_list) < 2:\n",
        "          indices = [idx_list]\n",
        "    \n",
        "      # get score for each candidate summary and sort them in descending order\n",
        "      score = []\n",
        "      for i in indices:\n",
        "          i = list(i)\n",
        "          i.sort()\n",
        "          # write dec\n",
        "          dec = torch.tensor([])\n",
        "          for j in i:\n",
        "              sent = sentence_id_list[j]\n",
        "              sent = sent[1:]\n",
        "              sep_token_idx = 0\n",
        "              for token_idx in range(len(sent)):\n",
        "                if sent[token_idx] == 1: break\n",
        "                else:sep_token_idx += 1\n",
        "              sent = sent[:sep_token_idx]\n",
        "              dec = torch.cat([dec,sent],dim=0)\n",
        "          \n",
        "          dec = torch.cat([cls_token,dec,sep_token],dim=0)\n",
        "          dec_out = extract_model(dec)\n",
        "          score.append((dec, get_score(doc_emb[batch_idx,:],summary_emb[batch_idx,:], dec_out['last_hidden_states'][0,:])))\n",
        "      \n",
        "      score.sort(key=lambda x : x[1], reverse=True)\n",
        "      score = score[:candidate_num]\n",
        "      candidate_ids_ind = [k for k,_ in score]\n",
        "      candidate_ids.append(candidate_ids_ind)\n",
        "\n",
        "    return candidate_ids"
      ],
      "metadata": {
        "id": "zw3Cv452e1y1"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MatchSum(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, candidate_num, hidden_size=768):\n",
        "        super(MatchSum, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.candidate_num  = candidate_num\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def forward(self, text_id, summary_id,list_of_sentence_id):\n",
        "        \n",
        "        batch_size = text_id.size(0)\n",
        "        pad_id = 1 \n",
        "\n",
        "        # get document embedding\n",
        "        input_mask = ~(text_id == pad_id)\n",
        "        out = self.encoder(text_id, attention_mask=input_mask)['last_hidden_state'] # last layer\n",
        "        doc_emb = out[:, 0, :]\n",
        "        assert doc_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "        \n",
        "        # get summary embedding\n",
        "        input_mask = ~(summary_id == pad_id)\n",
        "        out = self.encoder(summary_id, attention_mask=input_mask)['last_hidden_state'] # last layer\n",
        "        summary_emb = out[:, 0, :]\n",
        "        assert summary_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "\n",
        "        # get summary score\n",
        "        summary_score = torch.cosine_similarity(summary_emb, doc_emb, dim=-1)\n",
        "\n",
        "        # get candidate embedding\n",
        "        candidate_id = get_candidate_id(doc_emb,summary_emb,list_of_sentence_id, self.candidate_num, self.encoder)\n",
        "        candidate_id = candidate_id.view(-1, candidate_id.size(-1))\n",
        "        input_mask = ~(candidate_id == pad_id)\n",
        "        out = self.encoder(candidate_id, attention_mask=input_mask)[0]\n",
        "        candidate_emb = out[:, 0, :].view(batch_size, self.candidate_num, self.hidden_size)  # [batch_size, candidate_num, hidden_size]\n",
        "        assert candidate_emb.size() == (batch_size, self.candidate_num, self.hidden_size)\n",
        "        \n",
        "        # get candidate score\n",
        "        doc_emb = doc_emb.unsqueeze(1).expand_as(candidate_emb)\n",
        "        score = torch.cosine_similarity(candidate_emb, doc_emb, dim=-1) # [batch_size, candidate_num]\n",
        "        golden_list = torch.argmax(score,dim=1)\n",
        "        assert score.size() == (batch_size, self.candidate_num)\n",
        "\n",
        "        return {'score': score, 'summary_score': summary_score, 'summary_list':candidate_id}"
      ],
      "metadata": {
        "id": "YiYH-dn7VYLv"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MarginRankingLoss():      \n",
        "    \n",
        "    def __init__(self, margin, score=None, summary_score=None):\n",
        "        super(MarginRankingLoss, self).__init__()\n",
        "        self._init_param_map(score=score, summary_score=summary_score)\n",
        "        self.margin = margin\n",
        "        self.loss_func = torch.nn.MarginRankingLoss(margin)\n",
        "\n",
        "    def get_loss(self, score, summary_score):\n",
        "        \n",
        "        # equivalent to initializing TotalLoss to 0\n",
        "        # here is to avoid that some special samples will not go into the following for loop\n",
        "        ones = torch.ones(score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss = loss_func(score, score, ones)\n",
        "\n",
        "        # candidate loss\n",
        "        n = score.size(1)\n",
        "        for i in range(1, n):\n",
        "            pos_score = score[:, :-i]\n",
        "            neg_score = score[:, i:]\n",
        "            pos_score = pos_score.contiguous().view(-1)\n",
        "            neg_score = neg_score.contiguous().view(-1)\n",
        "            ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "            loss_func = torch.nn.MarginRankingLoss(self.margin * i)\n",
        "            TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "\n",
        "        # gold summary loss\n",
        "        pos_score = summary_score.unsqueeze(-1).expand_as(score)\n",
        "        neg_score = score\n",
        "        pos_score = pos_score.contiguous().view(-1)\n",
        "        neg_score = neg_score.contiguous().view(-1)\n",
        "        ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "        \n",
        "        return TotalLoss"
      ],
      "metadata": {
        "id": "F8Jbgz4x5jeF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class rdass:\n",
        "  def __init__(self,encoder,device):\n",
        "    self.encoder = encoder\n",
        "    for param in self.encoder.parameters():\n",
        "        param.requires_grad = False\n",
        "  \n",
        "  def __call__(self, text_ids = None, label_ids = None, answer_ids = None):\n",
        "    vector_text = self.encoder(text_ids).detach()['hidden_states'][-1][0,:] # vector_d\n",
        "    vector_label = self.encoder(label_ids).detach()['hidden_states'][-1][0,:] # vector_r\n",
        "    vector_answer = self.encoder(answer_ids).detach()['hidden_states'][-1][0,:] # vector_p\n",
        "\n",
        "    return get_score(vector_text,vector_label,vector_answer)"
      ],
      "metadata": {
        "id": "KcIcbmwnyWEZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model-Load & train code\n",
        "\n",
        "- Encoder -> KoBART\n",
        "- GLM 을 제외한 제일 성능 좋은 모델이고 한국어로 train이 되어 있어 선정함"
      ],
      "metadata": {
        "id": "iKJb-DcKynhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
        "summary_model = MatchSum(encoder = model, candidate_num = 5, hidden_size=768) # hidden_size == vocab size?\n",
        "\n",
        "model_for_eval = AutoModel.from_pretrained(\"klue/roberta-small\")\n",
        "tokenizer_for_eval = AutoTokenizer.from_pretrained(\"klue/roberta-small\")\n",
        "metric = rdass(model_for_eval,device)\n",
        "\n",
        "N_EPOCHS = 3\n",
        "optimizer = SGD(model.parameters(),lr =0.0001)\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer,T_0 = 1,T_mult = 1)"
      ],
      "metadata": {
        "id": "DelT9Z9wfbVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c906fd5-cef0-4ead-89cb-f39d23cd1b10"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobart_base_cased_ff4bda5738.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "summary_model.to(device)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "    print(f\"*****Epoch {epoch} Total Step {len(train_dataloader)}*****\")\n",
        "    total_loss, batch_loss, batch_step = 0,0,0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch_step+=1\n",
        "        print(batch[\"text_input_ids\"].shape)\n",
        "        text_input_ids = batch[\"text_input_ids\"].to(device)        \n",
        "        label_input_ids = batch[\"labels_input_ids\"].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        output = summary_model.forward(text_input_ids, label_input_ids,batch[\"sentence_input_ids\"])\n",
        "        loss = MarginRankingLoss(output[\"score\"],output[\"summary_score\"])\n",
        "\n",
        "        # loss 계산\n",
        "        loss.backward()\n",
        "        # optimizer 업데이트\n",
        "        optimizer.step()\n",
        "        # scheduler 업데이트\n",
        "        scheduler.step()\n",
        "\n",
        "        batch_loss += loss.item()\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        rdass_loss = metric(text = text_input_ids,label=  label_input_ids, answer = output['golden_summary'])\n",
        "        if (step%500 == 0) and (step!=0):\n",
        "            print(f\"Step: {step} Loss: {batch_loss/batch_step:.4f} lr: {optimizer.param_groups[0]['lr']:.4f}\")\n",
        "            # 변수 초기화    \n",
        "            batch_loss, batch_step = 0,0\n",
        "    \n",
        "    print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "    print(f\"*****Epoch {epoch} Train Finished*****\\n\")\n",
        "    "
      ],
      "metadata": {
        "id": "KmtCKyr2D0YE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "114daabd-c6e3-4527-eb4c-6673801d8931"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-dfa99fcc8327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msummary_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "j4CmhmsXEcMX",
        "outputId": "a95055fe-4bdd-4721-ce67-4da7adfdbde7"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-817a089757f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36mget_summarized_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m         end = ([self[i]\n\u001b[1;32m    272\u001b[0m                for i in range(len(self) - PRINT_OPTS.edgeitems, len(self))])\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    271\u001b[0m         end = ([self[i]\n\u001b[1;32m    272\u001b[0m                for i in range(len(self) - PRINT_OPTS.edgeitems, len(self))])\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36mget_summarized_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mPRINT_OPTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(text_input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "EPUBRFJJEsN_",
        "outputId": "16f0d8cd-2d3e-466a-bae8-eb8eea243de3"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-5b6855007af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3121\u001b[0m         \"\"\"\n\u001b[1;32m   3122\u001b[0m         \u001b[0;31m# Convert inputs to python lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3123\u001b[0;31m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3125\u001b[0m         return self._decode(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto_py_obj\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_is_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad_id = 1\n",
        "input_mask = ~(text_input_ids == pad_id)"
      ],
      "metadata": {
        "id": "Vxus2c6vGsiE"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.forward(text_input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "DhggqAruG9_Z",
        "outputId": "d97aed4c-ea9a-490e-bf75-3e4a92f1ab0e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-3bdf72d350d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             )\n\u001b[1;32m   1159\u001b[0m         \u001b[0;31m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0membed_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "aKIQiz_sIBXq",
        "outputId": "2ab99dbb-f0d8-45c0-cd02-1d79736f28ab"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-7750c7ee2c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    }
  ]
}