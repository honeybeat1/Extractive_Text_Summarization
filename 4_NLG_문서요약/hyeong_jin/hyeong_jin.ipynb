{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcDvXF_FGN9F"
      },
      "source": [
        "### 설정 + 필요한 모델 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_oPnfM62iN",
        "outputId": "643754af-d7a8-4e22-d99f-aad28a247fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZL4Q4KFTvJ3",
        "outputId": "72084b97-b954-4e06-ad84-09f0e63d8a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 52.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXS8BohW9mHg",
        "outputId": "36272267-a913-47ea-8d07-921e0c62fa2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/SKT-AI/KoBART\n",
            "  Cloning https://github.com/SKT-AI/KoBART to /tmp/pip-req-build-85mwdeny\n",
            "  Running command git clone -q https://github.com/SKT-AI/KoBART /tmp/pip-req-build-85mwdeny\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.23-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from kobart==0.5.1) (1.3.5)\n",
            "Collecting pytorch-lightning==1.2.1\n",
            "  Downloading pytorch_lightning-1.2.1-py3-none-any.whl (814 kB)\n",
            "\u001b[K     |████████████████████████████████| 814 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting transformers==4.3.3\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 37.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (2.8.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (4.63.0)\n",
            "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (6.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 56.7 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.1->kobart==0.5.1) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->kobart==0.5.1) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (4.11.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (0.0.49)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart==0.5.1) (21.3)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->kobart==0.5.1) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart==0.5.1) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart==0.5.1) (3.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart==0.5.1) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart==0.5.1) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 60.1 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.23\n",
            "  Downloading botocore-1.24.23-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 30.9 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.23->boto3->kobart==0.5.1) (2.8.2)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->kobart==0.5.1) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->kobart==0.5.1) (2018.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart==0.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart==0.5.1) (1.1.0)\n",
            "Building wheels for collected packages: kobart, future\n",
            "  Building wheel for kobart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobart: filename=kobart-0.5.1-py3-none-any.whl size=9562 sha256=2157afb699b772738a46af43005f7bddcbde304eacf092b4e1f14e71c2068b6c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hzng_zpr/wheels/6e/55/c4/bd4fede223bc304089ac8da2a2099a69db3fcd4b0e853383f5\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=7a282793bdc120dd40b0e66473101f8b56d4583d27fa5817fcf176c4f375f772\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built kobart future\n",
            "Installing collected packages: urllib3, multidict, frozenlist, yarl, jmespath, asynctest, async-timeout, aiosignal, fsspec, botocore, aiohttp, torch, tokenizers, s3transfer, future, transformers, pytorch-lightning, boto3, kobart\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.11.6\n",
            "    Uninstalling tokenizers-0.11.6:\n",
            "      Successfully uninstalled tokenizers-0.11.6\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.17.0\n",
            "    Uninstalling transformers-4.17.0:\n",
            "      Successfully uninstalled transformers-4.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 boto3-1.21.23 botocore-1.24.23 frozenlist-1.3.0 fsspec-2022.2.0 future-0.18.2 jmespath-1.0.0 kobart-0.5.1 multidict-6.0.2 pytorch-lightning-1.2.1 s3transfer-0.5.2 tokenizers-0.10.3 torch-1.7.1 transformers-4.3.3 urllib3-1.25.11 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/SKT-AI/KoBART #egg=kobart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXrqeNnnQ_eN",
        "outputId": "78c4944b-6a22-49a6-bac8-71225f6e9228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.11-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.8-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 48.1 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=25a6f5b2f3e665a191950eea15aff67563aa3a3d9ac9ebb97e9d225658389e29\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.8 setproctitle-1.2.2 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.11 yaspin-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KUfwH5tXtEyQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os \n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "\n",
        "from google.colab import drive\n",
        "import re\n",
        "from konlpy.tag import Okt\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from itertools import combinations\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "\n",
        "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
        "from transformers import AutoModel, BartModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58DHYlQkt95N",
        "outputId": "518896b3-f724-442d-8584-12102276ae30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# available GPUs : 1\n",
            "GPU name : Tesla P100-PCIE-16GB\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# seed\n",
        "seed = 7777\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "# device type\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"# available GPUs : {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU name : {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7kzv5U25HUQ"
      },
      "source": [
        "### 원본 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHXL22kYyWxV",
        "outputId": "7f81cd1b-c5dc-4907-a789-f096ad8b423b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j7Yjhg1D1s76"
      },
      "outputs": [],
      "source": [
        "csv_test = pd.read_csv(\"/content/drive/MyDrive/NLP/sports_news_data - sports_news_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "3U1QMZqj2Lcd",
        "outputId": "82031331-0bed-48bc-ae7f-215a960e0522"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-05d3a471-3774-43d8-bfd9-2cc38f5b9444\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>PUBLISH_DT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>스털링 다이빙 논란 종결?… “오른쪽 다리 접촉 있었잖아”</td>\n",
              "      <td>[스포탈코리아] 유럽축구연맹(UEFA) 유로 2020 심판위원장 로베르토 로세티가 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‘디 마리아 없다’ 유로X코파 베스트11, 이탈리아만 7명</td>\n",
              "      <td>[스포탈코리아] 유로 2020과 코파 아메리카 2021로 베스트11을 만든다면 어떤...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‘슈퍼컴퓨터 예측’ 맨시티 우승-맨유 4위… 토트넘은 ‘6위’</td>\n",
              "      <td>[스포탈코리아] 새 시즌이 시작하기도 전에 슈퍼컴퓨터가 예상한 순위가 나왔다.\\n\\...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“이재성, 완벽한 프로… 마인츠서 성공할 것” 킬 디렉터의 애정 듬뿍 응원</td>\n",
              "      <td>[스포탈코리아] 홀슈타인 킬 우베 스토버 디렉터가 이재성을 향해 응원 메시지를 띄웠...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‘홈킷과 딴판’ 바르사 팬들, NEW 어웨이 셔츠 호평… “가장 좋아하는 색!”</td>\n",
              "      <td>[스포탈코리아] FC 바르셀로나가 새 시즌 원정 유니폼을 공개했다. 팬들은 만족스럽...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>긴급 수혈된 바르사 NO.9, 1년 반 만에 떠난다… ‘EPL행 유력’</td>\n",
              "      <td>[스포탈코리아] FC 바르셀로나는 새 시즌을 앞두고 선수단 정리가 한창이다. 잉여 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[김남구의 유럽통신] 황의조, 손흥민 소속사와 손잡다… CAA Base와 계약</td>\n",
              "      <td>[스포탈코리아=파리(프랑스)] 황의조(지롱댕 드 보르도)가 한국 선수로는 3번째로 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\"메시 종신은 축복!\"…스폰서 5년 더 보장, 바르셀로나 함박웃음</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34)가 FC바르셀로나에 남는다. 연봉을 절반 삭감하지...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[오피셜] 눈물 흘렸던 '37세 전설' 로번, 두 번째 현역 은퇴 발표</td>\n",
              "      <td>[스포탈코리아] 네덜란드 축구스타 아르연 로번(37)이 현역 은퇴를 밝혔다. \\n\\...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100세' 메시팬 할아버지, 748골 수기 작성…메시도 감사 인사</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34)는 프로 데뷔하고 748골을 터뜨렸다. 전산화 하...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>475억원이면 맨유 떠난다…시메오네의 픽, 부활한 린가드</td>\n",
              "      <td>[스포탈코리아] 스페인 프리메라리가 챔피언 아틀레티코 마드리드가 부활한 제시 린가드...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>토트넘, 케인 대체자 ‘세리에A 21골+810억 골잡이’ 찾았다</td>\n",
              "      <td>[스포탈코리아] 토트넘 홋스퍼가 해리 케인(27) 이탈을 대비하고 있다. 이탈리아 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1,585억에 케인 불발 맨시티, 329경기 294골 킬러 영입 추진</td>\n",
              "      <td>[스포탈코리아] 맨체스터 시티가 확실한 킬러를 찾기 위해 분주하다. \\n\\n맨시티는...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>맨유 관심 프랑스 18세 미드필더, ‘레알이나 바르사 갈 건데요’</td>\n",
              "      <td>[스포탈코리아] ‘잉글랜드보다 스페인이 더 끌리네요’\\n\\n빅클럽들이 군침을 흘리고...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>“메시, 월드컵 4회 우승해도 마라도나 못 넘어” 전설의 주장</td>\n",
              "      <td>[스포탈코리아] 리오넬 메시(34, FC바르셀로나)가 선배인 故 디에고 마라도와 또...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>모리뉴, 손흥민 전 동료에게 “동물이다”</td>\n",
              "      <td>[스포탈코리아] AS로마 수장 조세 모리뉴(58)가 손흥민(29, 토트넘 홋스퍼)의...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>도르트문트, 첼시의 홀란 영입 제안 거절(英 스카이스포츠)</td>\n",
              "      <td>[스포탈코리아] 보루시아 도르트문트가 뜨거운 감자 엘링 홀란(20)을 붙잡는다.\\n...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>레노버, 인터 밀란과 파트너십 강화… 유니폼 스폰서로 나서</td>\n",
              "      <td>[스포탈코리아] 세계 1위 PC 및 스마트 디바이스 업체 레노버가 인터 밀란과 파트...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>‘다시 돌아와!’ 웨스트햄, 임대 전설 쓰고 떠난 린가드 영입 추진</td>\n",
              "      <td>[스포탈코리아] 웨스트햄 유나이티드가 제시 린가드(맨체스터 유나이티드) 영입에 원하...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>바르셀로나 충격 요구 : 그리즈만 = 사울+200억원, 사울+선수 1명</td>\n",
              "      <td>[스포탈코리아] FC바르셀로나가 아틀레티코 마드리드에 트레이드를 요구했다. \\n\\n...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05d3a471-3774-43d8-bfd9-2cc38f5b9444')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05d3a471-3774-43d8-bfd9-2cc38f5b9444 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05d3a471-3774-43d8-bfd9-2cc38f5b9444');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                           TITLE  \\\n",
              "0               스털링 다이빙 논란 종결?… “오른쪽 다리 접촉 있었잖아”   \n",
              "1               ‘디 마리아 없다’ 유로X코파 베스트11, 이탈리아만 7명   \n",
              "2             ‘슈퍼컴퓨터 예측’ 맨시티 우승-맨유 4위… 토트넘은 ‘6위’   \n",
              "3      “이재성, 완벽한 프로… 마인츠서 성공할 것” 킬 디렉터의 애정 듬뿍 응원   \n",
              "4   ‘홈킷과 딴판’ 바르사 팬들, NEW 어웨이 셔츠 호평… “가장 좋아하는 색!”   \n",
              "5        긴급 수혈된 바르사 NO.9, 1년 반 만에 떠난다… ‘EPL행 유력’   \n",
              "6    [김남구의 유럽통신] 황의조, 손흥민 소속사와 손잡다… CAA Base와 계약   \n",
              "7           \"메시 종신은 축복!\"…스폰서 5년 더 보장, 바르셀로나 함박웃음   \n",
              "8        [오피셜] 눈물 흘렸던 '37세 전설' 로번, 두 번째 현역 은퇴 발표   \n",
              "9           100세' 메시팬 할아버지, 748골 수기 작성…메시도 감사 인사   \n",
              "10               475억원이면 맨유 떠난다…시메오네의 픽, 부활한 린가드   \n",
              "11           토트넘, 케인 대체자 ‘세리에A 21골+810억 골잡이’ 찾았다   \n",
              "12        1,585억에 케인 불발 맨시티, 329경기 294골 킬러 영입 추진   \n",
              "13          맨유 관심 프랑스 18세 미드필더, ‘레알이나 바르사 갈 건데요’   \n",
              "14            “메시, 월드컵 4회 우승해도 마라도나 못 넘어” 전설의 주장   \n",
              "15                        모리뉴, 손흥민 전 동료에게 “동물이다”   \n",
              "16              도르트문트, 첼시의 홀란 영입 제안 거절(英 스카이스포츠)   \n",
              "17              레노버, 인터 밀란과 파트너십 강화… 유니폼 스폰서로 나서   \n",
              "18         ‘다시 돌아와!’ 웨스트햄, 임대 전설 쓰고 떠난 린가드 영입 추진   \n",
              "19       바르셀로나 충격 요구 : 그리즈만 = 사울+200억원, 사울+선수 1명   \n",
              "\n",
              "                                              CONTENT  PUBLISH_DT  \n",
              "0   [스포탈코리아] 유럽축구연맹(UEFA) 유로 2020 심판위원장 로베르토 로세티가 ...  2021-07-15  \n",
              "1   [스포탈코리아] 유로 2020과 코파 아메리카 2021로 베스트11을 만든다면 어떤...  2021-07-15  \n",
              "2   [스포탈코리아] 새 시즌이 시작하기도 전에 슈퍼컴퓨터가 예상한 순위가 나왔다.\\n\\...  2021-07-15  \n",
              "3   [스포탈코리아] 홀슈타인 킬 우베 스토버 디렉터가 이재성을 향해 응원 메시지를 띄웠...  2021-07-15  \n",
              "4   [스포탈코리아] FC 바르셀로나가 새 시즌 원정 유니폼을 공개했다. 팬들은 만족스럽...  2021-07-15  \n",
              "5   [스포탈코리아] FC 바르셀로나는 새 시즌을 앞두고 선수단 정리가 한창이다. 잉여 ...  2021-07-15  \n",
              "6   [스포탈코리아=파리(프랑스)] 황의조(지롱댕 드 보르도)가 한국 선수로는 3번째로 ...  2021-07-15  \n",
              "7   [스포탈코리아] 리오넬 메시(34)가 FC바르셀로나에 남는다. 연봉을 절반 삭감하지...  2021-07-15  \n",
              "8   [스포탈코리아] 네덜란드 축구스타 아르연 로번(37)이 현역 은퇴를 밝혔다. \\n\\...  2021-07-15  \n",
              "9   [스포탈코리아] 리오넬 메시(34)는 프로 데뷔하고 748골을 터뜨렸다. 전산화 하...  2021-07-15  \n",
              "10  [스포탈코리아] 스페인 프리메라리가 챔피언 아틀레티코 마드리드가 부활한 제시 린가드...  2021-07-15  \n",
              "11  [스포탈코리아] 토트넘 홋스퍼가 해리 케인(27) 이탈을 대비하고 있다. 이탈리아 ...  2021-07-15  \n",
              "12  [스포탈코리아] 맨체스터 시티가 확실한 킬러를 찾기 위해 분주하다. \\n\\n맨시티는...  2021-07-15  \n",
              "13  [스포탈코리아] ‘잉글랜드보다 스페인이 더 끌리네요’\\n\\n빅클럽들이 군침을 흘리고...  2021-07-15  \n",
              "14  [스포탈코리아] 리오넬 메시(34, FC바르셀로나)가 선배인 故 디에고 마라도와 또...  2021-07-15  \n",
              "15  [스포탈코리아] AS로마 수장 조세 모리뉴(58)가 손흥민(29, 토트넘 홋스퍼)의...  2021-07-15  \n",
              "16  [스포탈코리아] 보루시아 도르트문트가 뜨거운 감자 엘링 홀란(20)을 붙잡는다.\\n...  2021-07-15  \n",
              "17  [스포탈코리아] 세계 1위 PC 및 스마트 디바이스 업체 레노버가 인터 밀란과 파트...  2021-07-15  \n",
              "18  [스포탈코리아] 웨스트햄 유나이티드가 제시 린가드(맨체스터 유나이티드) 영입에 원하...  2021-07-15  \n",
              "19  [스포탈코리아] FC바르셀로나가 아틀레티코 마드리드에 트레이드를 요구했다. \\n\\n...  2021-07-15  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "csv_test.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhpUnNfR63sq"
      },
      "source": [
        "### 전처리\n",
        "- 중복 및 결측치 제거\n",
        "- 크롤링 상에서 생긴 쓸모 없는 문구 처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QgS0iTJ8QT0F"
      },
      "outputs": [],
      "source": [
        "def preprocess(string):\n",
        "    str_list = string.split('\\n\\n') # \\n\\n 기준으로 분리\n",
        "    str_list[0] = str_list[0].replace('[스포탈코리아] ', '') # [스포탈코리아] 삭제\n",
        "    \n",
        "    result = []\n",
        "    for strg in str_list:\n",
        "        strg = re.sub(r'\\([^)]*\\)|\\[[^)]*\\]|\\<[^)]*\\>', ' ', strg) # 괄호와 그 안에 문자 제거\n",
        "\n",
        "        if '기자' in strg: # 기자 이름이 들어간 경우 기자이름 삭제\n",
        "            strg = strg.split('기자')[-1]\n",
        "        if '다.' in strg: # 문장 단위로 분리\n",
        "            strg = strg.split('. ')\n",
        "            for s in strg:\n",
        "                if s != '':\n",
        "                    result.append(s)\n",
        "            \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uMpyTPRiQwWb"
      },
      "outputs": [],
      "source": [
        "def special(str_list):\n",
        "    regex = r\"[^가-힣a-zA-Z0-9 ]\" # 특수 문자 제거\n",
        "    for i in range(len(str_list)):\n",
        "        str_list[i] = re.sub(regex, '', str_list[i])\n",
        "\n",
        "    return str_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MQSj-oMeQ5Yb"
      },
      "outputs": [],
      "source": [
        "def special_title(string):\n",
        "    regex = r\"[^가-힣a-zA-Z0-9 ]\" # 특수 문자 제거\n",
        "    string = re.sub(regex, '', string)\n",
        "\n",
        "    return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SA9s6Ts52cYZ"
      },
      "outputs": [],
      "source": [
        "trimmed_data=csv_test.dropna().copy()\n",
        "  \n",
        "idx = trimmed_data['CONTENT'].drop_duplicates().index\n",
        "trimmed_data = trimmed_data.loc[idx]\n",
        "\n",
        "idx = trimmed_data['TITLE'].drop_duplicates().index\n",
        "trimmed_data = trimmed_data.loc[idx]\n",
        "\n",
        "trimmed_data['CONTENT'] = trimmed_data['CONTENT'].apply(preprocess)\n",
        "trimmed_data['CONTENT'] = trimmed_data['CONTENT'].apply(special)\n",
        "trimmed_data['TITLE'] = trimmed_data['TITLE'].apply(special_title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "trwV6MQRMnwh"
      },
      "outputs": [],
      "source": [
        "idx_list=[]\n",
        "for i in range(len(trimmed_data)):\n",
        "  if len(trimmed_data['CONTENT'].iloc[i]) < 4:\n",
        "    idx_list.append(trimmed_data.iloc[i].name)\n",
        "\n",
        "abandoned_data = trimmed_data.loc[idx_list]\n",
        "trimmed_data = trimmed_data.drop(idx_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWzYDTh748dO",
        "outputId": "a095d85b-9c64-4aea-fe23-880b96d53412"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8358"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trimmed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOrftvJW63Dt"
      },
      "source": [
        "- 띄어쓰기 및 불용어 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sNfaAWH6fTI",
        "outputId": "76d807d5-3ea7-4691-f187-7a76b1340908"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ranks.nl'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Korean stop words: 677\n"
          ]
        }
      ],
      "source": [
        "# 한국어 불용어 리스트 크롤링\n",
        "\n",
        "\n",
        "url = \"https://www.ranks.nl/stopwords/korean\"\n",
        "response = requests.get(url, verify = False)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    content = soup.select_one('#article178ebefbfb1b165454ec9f168f545239 > div.panel-body > table > tbody > tr')\n",
        "    stop_words=[]\n",
        "    for x in content.strings:\n",
        "        x=x.strip()\n",
        "        if x:\n",
        "            stop_words.append(x)\n",
        "    print(f\"# Korean stop words: {len(stop_words)}\")\n",
        "else:\n",
        "    print(response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lCXhA4D_WBO",
        "outputId": "02d3e4e7-1e1f-4a15-c72d-4a6ed5c922c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8358/8358 [06:05<00:00, 22.87it/s]\n"
          ]
        }
      ],
      "source": [
        "okt = Okt()\n",
        "for i in tqdm(range(len(trimmed_data))):\n",
        "  temp_data = okt.morphs(trimmed_data[\"TITLE\"].iloc[i])\n",
        "  temp_list = []\n",
        "\n",
        "  for word in temp_data:\n",
        "    if word in stop_words: continue\n",
        "    temp_list.append(word)\n",
        "  \n",
        "  trimmed_data[\"TITLE\"].iloc[i] = \" \".join(temp_list)\n",
        "\n",
        "  temp_list = []\n",
        "  for sentence in trimmed_data[\"CONTENT\"].iloc[i]:\n",
        "    temp_data = okt.morphs(sentence)\n",
        "    temp_sentecne_list = []\n",
        "    \n",
        "    for word in temp_data:\n",
        "      if word in stop_words: continue\n",
        "      temp_sentecne_list.append(word)\n",
        "    \n",
        "    temp_sentence = \" \".join(temp_sentecne_list)\n",
        "    temp_list.append(temp_sentence)\n",
        "  \n",
        "  trimmed_data[\"CONTENT\"].iloc[i] = temp_list\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7Mg_VIivfdpZ",
        "outputId": "e68acf4b-27f6-4fcd-b942-c432ed0f9f6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-72e76e84-7b21-44c4-adb0-c0c999933b6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>PUBLISH_DT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아</td>\n",
              "      <td>[유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>디 마리아 없다 유로 X 코파 베스트 11 이탈리아 만 7 명</td>\n",
              "      <td>[지난달 시작 된 유로 코파 아메리카 11일 끝 막 내렸다, 이탈리아 는 결승전 잉...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>슈퍼컴퓨터 예측 맨시티 우승 맨유 4 위 토트넘 은 6 위</td>\n",
              "      <td>[새 시즌 시작 하기도 전 슈퍼컴퓨터 예상 한 순위 나왔다, 영국 매체 스포츠 바이...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이재성 완벽한 프로 마인츠 서 성공할 킬 디렉터 애정 듬뿍 응원</td>\n",
              "      <td>[홀슈타인 킬 우베 스토 버 디렉터 이재성 향 해 응원 메시지 띄웠다, 이재성 은 ...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>홈킷 딴판 바르사 팬 NEW 웨이 셔츠 호평 가장 좋아하는 색</td>\n",
              "      <td>[FC 바르셀로나 새 시즌 원정 유니폼 공개 했다, 팬 은 만족스럽다는 반응 이다,...</td>\n",
              "      <td>2021-07-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72e76e84-7b21-44c4-adb0-c0c999933b6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72e76e84-7b21-44c4-adb0-c0c999933b6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72e76e84-7b21-44c4-adb0-c0c999933b6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 TITLE  \\\n",
              "0         스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아   \n",
              "1   디 마리아 없다 유로 X 코파 베스트 11 이탈리아 만 7 명   \n",
              "2     슈퍼컴퓨터 예측 맨시티 우승 맨유 4 위 토트넘 은 6 위   \n",
              "3  이재성 완벽한 프로 마인츠 서 성공할 킬 디렉터 애정 듬뿍 응원   \n",
              "4   홈킷 딴판 바르사 팬 NEW 웨이 셔츠 호평 가장 좋아하는 색   \n",
              "\n",
              "                                             CONTENT  PUBLISH_DT  \n",
              "0  [유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나...  2021-07-15  \n",
              "1  [지난달 시작 된 유로 코파 아메리카 11일 끝 막 내렸다, 이탈리아 는 결승전 잉...  2021-07-15  \n",
              "2  [새 시즌 시작 하기도 전 슈퍼컴퓨터 예상 한 순위 나왔다, 영국 매체 스포츠 바이...  2021-07-15  \n",
              "3  [홀슈타인 킬 우베 스토 버 디렉터 이재성 향 해 응원 메시지 띄웠다, 이재성 은 ...  2021-07-15  \n",
              "4  [FC 바르셀로나 새 시즌 원정 유니폼 공개 했다, 팬 은 만족스럽다는 반응 이다,...  2021-07-15  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmed_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no71C-gm-b3r",
        "outputId": "f001a6d2-74f0-4089-e8df-0d176c1251dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TITLE                              스털링 다이빙 논란 종결 오른쪽 다리 접촉 있었잖아\n",
            "CONTENT       [유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나...\n",
            "PUBLISH_DT                                           2021-07-15\n",
            "Name: 0, dtype: object\n",
            "['유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나온 판정 논란 정심 이라고 공언 했다', '지난 8일 잉글랜드 덴마크 는 유로 2020 4 강 결승 티켓 두고 격돌 했다', '연장 접전 끝 잉글랜드 21 이겼다', '경기 후 논란 불거졌다', '11 팽팽 하던 연장 전반 12분 라 힘 스털링 드리블 돌파 하던 중 요아킴 멜레 마티아스 옌센 사이 넘어졌다', '심판 은 곧장 페널티 스팟 찍었다', '비디오 판독 실과 의견 나눈 뒤 에도 원심 유지 했다', '페널티킥 얻은 잉글랜드 는 해리 케인 실축 했지만 흐른 볼 밀어 넣어 결승 티켓 따냈다', '장면 두고 갑론 박 펼쳐졌다', '스털링 은 경기 후 인터뷰 명백한 페널티킥 이라고 주장 했지만 전문가 의견 은 달랐다', '조제 모리뉴 AS 로마 감독 아르 센 벵거 전 아스널 감독 은 페널티킥 아니다고 입 모았다', '많은 이야기 흘러나오는 가운데 유로 2020 심판 위원장 로세티 오심 아니라는 입장 내놨다', '로세티 위원장 은 14일 영국 매체 가디언 인터뷰 주심 은 5 번 수비수 주목 했다', '수비수 볼 터치 하지 않았다고 봤다', '멜레 오른쪽 다리 스털링 오른쪽 다리 접촉 한 확인 했다', '접촉 강도 논 할 수 있지만 는 항상 심판 의사결정 과정 중심 되길 바란다고 밝혔다', '로세티 위원장 심판 대표 해 의견 냈지만 오심 이라고 생각 하는 받아들일지는 미지수 다', '스털링 은 평소 에도 다이빙 논란 시 달려왔고 많은 머릿속 다이버 라는 인식 가득하기 때문 이다']\n",
            "0\n",
            "유럽 축구 연맹 유로 2020 심판 위원장 로베르토 로세티 잉글랜드 덴마크 전 나온 판정 논란 정심 이라고 공언 했다\n",
            "1\n",
            "지난 8일 잉글랜드 덴마크 는 유로 2020 4 강 결승 티켓 두고 격돌 했다\n",
            "2\n",
            "연장 접전 끝 잉글랜드 21 이겼다\n",
            "3\n",
            "경기 후 논란 불거졌다\n",
            "4\n",
            "11 팽팽 하던 연장 전반 12분 라 힘 스털링 드리블 돌파 하던 중 요아킴 멜레 마티아스 옌센 사이 넘어졌다\n",
            "5\n",
            "심판 은 곧장 페널티 스팟 찍었다\n",
            "6\n",
            "비디오 판독 실과 의견 나눈 뒤 에도 원심 유지 했다\n",
            "7\n",
            "페널티킥 얻은 잉글랜드 는 해리 케인 실축 했지만 흐른 볼 밀어 넣어 결승 티켓 따냈다\n",
            "8\n",
            "장면 두고 갑론 박 펼쳐졌다\n",
            "9\n",
            "스털링 은 경기 후 인터뷰 명백한 페널티킥 이라고 주장 했지만 전문가 의견 은 달랐다\n",
            "10\n",
            "조제 모리뉴 AS 로마 감독 아르 센 벵거 전 아스널 감독 은 페널티킥 아니다고 입 모았다\n",
            "11\n",
            "많은 이야기 흘러나오는 가운데 유로 2020 심판 위원장 로세티 오심 아니라는 입장 내놨다\n",
            "12\n",
            "로세티 위원장 은 14일 영국 매체 가디언 인터뷰 주심 은 5 번 수비수 주목 했다\n",
            "13\n",
            "수비수 볼 터치 하지 않았다고 봤다\n",
            "14\n",
            "멜레 오른쪽 다리 스털링 오른쪽 다리 접촉 한 확인 했다\n",
            "15\n",
            "접촉 강도 논 할 수 있지만 는 항상 심판 의사결정 과정 중심 되길 바란다고 밝혔다\n",
            "16\n",
            "로세티 위원장 심판 대표 해 의견 냈지만 오심 이라고 생각 하는 받아들일지는 미지수 다\n",
            "17\n",
            "스털링 은 평소 에도 다이빙 논란 시 달려왔고 많은 머릿속 다이버 라는 인식 가득하기 때문 이다\n"
          ]
        }
      ],
      "source": [
        "data_row = trimmed_data.iloc[0]\n",
        "print(data_row)\n",
        "\n",
        "text = data_row['CONTENT']\n",
        "print(text)\n",
        "\n",
        "for i, sentence in enumerate(text):\n",
        "  print(i)\n",
        "  print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa_-ie2sN7Gg",
        "outputId": "55003c88-7191-4560-865e-849e44ab9ae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "115\n"
          ]
        }
      ],
      "source": [
        "max_sentence_num = 0\n",
        "for i in range(len(trimmed_data)):\n",
        "  sentence_num = len(trimmed_data[\"CONTENT\"].iloc[i])\n",
        "  max_sentence_num = max(sentence_num,max_sentence_num)\n",
        "\n",
        "print(max_sentence_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwR_0Y2Uyc0g"
      },
      "source": [
        "#Extractive summarization - Matchsum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NQTQNZdTDuO"
      },
      "source": [
        "### Dataset & Dataloader 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YBy1iVi6PfKj"
      },
      "outputs": [],
      "source": [
        "def control_input_ids(input_ids_tensor,length,cls_token_num,sep_token_num,pad_token_num):\n",
        "  cur_length = len(input_ids_tensor)\n",
        "  cls_token = torch.tensor([cls_token_num])\n",
        "  sep_token = torch.tensor([sep_token_num])\n",
        "\n",
        "  if cur_length+2 > length:\n",
        "    input_ids_tensor = input_ids_tensor[:length-2]  # 길이가 넘치면 자른다\n",
        "    return torch.cat([cls_token,input_ids_tensor,sep_token])\n",
        "  else:\n",
        "    input_ids_tensor = torch.cat([cls_token,input_ids_tensor,sep_token])\n",
        "    padding_list = torch.tensor([pad_token_num]*(length - cur_length -2)) # 길이가 모자라면 padding token 을 채운다\n",
        "    return torch.cat([input_ids_tensor,padding_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bUCSPhOid36D"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(samples):\n",
        "  \n",
        "  text_ids = torch.empty(0,512)\n",
        "  labels_ids = torch.empty(0,32)\n",
        "  for sample in samples:\n",
        "    text_ids = torch.cat([text_ids,sample['text_input_ids'].unsqueeze(0)],dim=0) \n",
        "    labels_ids = torch.cat([labels_ids,sample['labels_input_ids'].unsqueeze(0)],dim=0)\n",
        "\n",
        "  sentence_input_ids = [sample['sentence_input_ids'] for sample in samples]\n",
        "  nn.utils.rnn.pad_sequence(sentence_input_ids,batch_first=True,padding_value = 1)\n",
        "\n",
        "  return dict(text_input_ids = text_ids.to(torch.int64), labels_input_ids = labels_ids.to(torch.int64), sentence_input_ids = sentence_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "V93s8-DRniiR"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(\n",
        "      self, data, tokenizer,\n",
        "      text_max_token_len = 512,\n",
        "      summary_max_token_len = 32\n",
        "        ):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = data\n",
        "    self.text_max_token_len = text_max_token_len\n",
        "    self.summary_max_token_len = summary_max_token_len\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    cls_token_num = 0\n",
        "    sep_token_num = 2\n",
        "    pad_token_num = 1\n",
        "    \n",
        "    data_row = self.data.iloc[index]\n",
        "    text = data_row['CONTENT']\n",
        "    \n",
        "    total_text_ids = torch.tensor([])\n",
        "    sentence_input_ids = torch.empty(0,32)\n",
        "\n",
        "    for sentence in text:\n",
        "      text_encoding_sentence = self.tokenizer(\n",
        "          sentence,return_tensors = \"pt\",add_special_tokens=False)\n",
        "      sentence_indiv_input_ids = text_encoding_sentence['input_ids'].flatten()\n",
        "      total_text_ids = torch.cat([total_text_ids,sentence_indiv_input_ids])\n",
        "\n",
        "      sentence_indiv_input_ids = control_input_ids(sentence_indiv_input_ids,self.summary_max_token_len,cls_token_num,sep_token_num,pad_token_num)\n",
        "      sentence_indiv_input_ids = sentence_indiv_input_ids.unsqueeze(0)\n",
        "      sentence_input_ids = torch.cat([sentence_input_ids,sentence_indiv_input_ids],dim=0)\n",
        "    \n",
        "    sentence_input_ids = sentence_input_ids.to(torch.int64)\n",
        "    total_text_ids = control_input_ids(total_text_ids,self.text_max_token_len,cls_token_num,sep_token_num,pad_token_num)    \n",
        "    total_text_ids = total_text_ids\n",
        "\n",
        "    labels = data_row['TITLE']\n",
        "    summary_encoding = self.tokenizer(\n",
        "        labels,\n",
        "        add_special_tokens = False,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "\n",
        "    labels_ids = summary_encoding['input_ids'].flatten()\n",
        "    labels_ids = control_input_ids(labels_ids,self.summary_max_token_len,cls_token_num,sep_token_num,pad_token_num)\n",
        "\n",
        "    return dict(text_input_ids = total_text_ids, labels_input_ids = labels_ids, sentence_input_ids = sentence_input_ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTYpg3eVs76S"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNA-2QR7uXMl",
        "outputId": "73b35c32-7c41-43bf-bcbc-a18d2a08cd62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/.cache/kobart_base_tokenizer_cased_cf74400bce.zip[██████████████████████████████████████████████████]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = get_kobart_tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hK1C6_KKrL7v"
      },
      "outputs": [],
      "source": [
        "whole_dataset = CustomDataset(trimmed_data,tokenizer)\n",
        "\n",
        "train_set_num = 8358//9*7\n",
        "train_dataset , valid_dataset = random_split(whole_dataset, [train_set_num,len(trimmed_data)-train_set_num])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 2, shuffle=True,collate_fn = custom_collate_fn)\n",
        "valid_dataloader =  DataLoader(valid_dataset, batch_size = 2, shuffle=False,collate_fn = custom_collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z5e_W-U93BH"
      },
      "source": [
        "### Matchsum\n",
        "\n",
        "- 평가 metric -> rdass\n",
        "- 기본적으로 모델에 스코어가 높은 5개의 단일 문장을 뽑고 뽑인 문장으로 만들어진 조합 가운데서 스코어가 높은 조합을 golden summary로 선정\n",
        "- loss 는 margin ranking loss 사용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2uoHyFZ8xJ6X"
      },
      "outputs": [],
      "source": [
        "def get_score(doc,label,answer):\n",
        "  score_1 = torch.cosine_similarity(doc,answer,dim=0)\n",
        "  score_2 = torch.cosine_similarity(label,answer,dim=0)\n",
        "  return score_1+score_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zw3Cv452e1y1"
      },
      "outputs": [],
      "source": [
        "def get_candidate_id(doc_emb,summary_emb,batch_sentence_id, candidate_num, extract_model,device):\n",
        "    cls_token = torch.tensor([0]).to(device)\n",
        "    sep_token = torch.tensor([2]).to(device)\n",
        "    candidate_ids = torch.empty([0,candidate_num,128]).to(device)\n",
        "    \n",
        "    for batch_idx, sentence_id_tensor in enumerate(batch_sentence_id):\n",
        "      sentence_id_tensor = sentence_id_tensor.to(device)\n",
        "      out = extract_model.forward(sentence_id_tensor)  #sentence_id_tensor = [문장 갯수,32개의 토큰]\n",
        "      hidden_states = out['last_hidden_state'][:,0,:] # [문장 갯수,token 갯수 ,768 dim_vec]\n",
        "      score_list= []\n",
        "      \n",
        "      for i in range(hidden_states.shape[0]):\n",
        "        score = get_score(doc = doc_emb[batch_idx,:], label = summary_emb[batch_idx,:], answer = hidden_states[i,:])\n",
        "        score_list.append((score,i))\n",
        "      \n",
        "      score_list.sort(key = lambda x: x[0],reverse=True)\n",
        "      idx_list = [idx for _,idx in score_list][:5]\n",
        "    \n",
        "      # get candidate summaries\n",
        "      # here is for CNN/DM: truncate each document into the 5 most important sentences (using BertExt), \n",
        "      # then select any 2 or 3 sentences to form a candidate summary, so there are C(5,2)+C(5,3)=20 candidate summaries.\n",
        "      # if you want to process other datasets, you may need to adjust these numbers according to specific situation.\n",
        "      indices = list(combinations(idx_list, 2))\n",
        "      indices += list(combinations(idx_list, 3))\n",
        "      if len(idx_list) < 2:\n",
        "          indices = [idx_list]\n",
        "    \n",
        "      # get score for each candidate summary and sort them in descending order\n",
        "      score = []\n",
        "      for i in indices:\n",
        "          i = list(i)\n",
        "          i.sort()\n",
        "          # write dec\n",
        "          dec = torch.tensor([]).to(device)\n",
        "          for j in i:\n",
        "              sent = sentence_id_tensor[j]\n",
        "              sent = sent[1:]\n",
        "              sep_token_idx = 0\n",
        "              for token_idx in range(len(sent)):\n",
        "                if sent[token_idx] == 2: break\n",
        "                else:sep_token_idx += 1\n",
        "              sent = sent[:sep_token_idx]\n",
        "              dec = torch.cat([dec,sent],dim=0)\n",
        "          \n",
        "          dec = torch.cat([cls_token,dec,sep_token],dim=0)\n",
        "          dec = dec.to(torch.int64)\n",
        "          dec_out = extract_model.forward(input_ids = dec.unsqueeze(0))\n",
        "          score.append((dec, get_score(doc_emb[batch_idx,:],summary_emb[batch_idx,:], dec_out['last_hidden_state'][0,0,:])))\n",
        "      \n",
        "      score.sort(key=lambda x : x[1], reverse=True)\n",
        "      score = score[:candidate_num]\n",
        "      \n",
        "      candidate_ids_ind= torch.empty(0,128).to(device)\n",
        "      for k,_ in score:\n",
        "        dec = k\n",
        "        if len(dec) < 128:\n",
        "          padding_list = torch.tensor([1]*(128-len(dec))).to(device)\n",
        "          dec = torch.cat([k,padding_list],dim=0)\n",
        "        else:\n",
        "          dec = dec[:128]\n",
        "\n",
        "        candidate_ids_ind = torch.cat([candidate_ids_ind,dec.unsqueeze(0)],dim = 0)\n",
        "\n",
        "      candidate_ids = torch.cat([candidate_ids,candidate_ids_ind.unsqueeze(0)],dim = 0)\n",
        "\n",
        "    return candidate_ids.to(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YiYH-dn7VYLv"
      },
      "outputs": [],
      "source": [
        "class MatchSum(nn.Module):  \n",
        "    def __init__ (self, encoder, candidate_num, device,hidden_size=768):\n",
        "        super(MatchSum, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.candidate_num  = candidate_num\n",
        "        self.encoder = encoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, text_id, summary_id,list_of_sentence_id):\n",
        "        \n",
        "        batch_size = text_id.size(0)\n",
        "        pad_id = 1 \n",
        "\n",
        "        # get document embedding\n",
        "        input_mask = ~(text_id == pad_id)\n",
        "        out = self.encoder(text_id, attention_mask=input_mask)['last_hidden_state'] # last layer\n",
        "        doc_emb = out[:, 0, :]\n",
        "        assert doc_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "        \n",
        "        # get summary embedding\n",
        "        input_mask = ~(summary_id == pad_id)\n",
        "        out = self.encoder(summary_id, attention_mask=input_mask)['last_hidden_state'] # last layer\n",
        "        summary_emb = out[:, 0, :]\n",
        "        assert summary_emb.size() == (batch_size, self.hidden_size) # [batch_size, hidden_size]\n",
        "\n",
        "        # get summary score\n",
        "        summary_score = torch.cosine_similarity(summary_emb, doc_emb, dim=-1)\n",
        "\n",
        "        # get candidate embedding\n",
        "        candidate_id = get_candidate_id(doc_emb,summary_emb,list_of_sentence_id, self.candidate_num, self.encoder,self.device) #[batch_size , candidate_num, token_num]\n",
        "        candidate_id = candidate_id.view(-1, candidate_id.size(-1)) \n",
        "        input_mask = ~(candidate_id == pad_id)\n",
        "        out = self.encoder(candidate_id, attention_mask=input_mask)['last_hidden_state'] \n",
        "        candidate_emb = out[:, 0, :].view(batch_size, self.candidate_num, self.hidden_size)  # [batch_size, candidate_num, hidden_size]\n",
        "        assert candidate_emb.size() == (batch_size, self.candidate_num, self.hidden_size)\n",
        "        \n",
        "        # get candidate score\n",
        "        doc_emb = doc_emb.unsqueeze(1).expand_as(candidate_emb)\n",
        "        score = torch.cosine_similarity(candidate_emb, doc_emb, dim=-1) # [batch_size, candidate_num]\n",
        "        golden_list = torch.argmax(score,dim=1)\n",
        "        assert score.size() == (batch_size, self.candidate_num)\n",
        "\n",
        "        return {'score': score, 'summary_score': summary_score, \n",
        "                'golden_summary':torch.cat([candidate_id[0,:].unsqueeze(1),candidate_id[self.candidate_num,:].unsqueeze(1)],dim=1)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "F8Jbgz4x5jeF"
      },
      "outputs": [],
      "source": [
        "class MarginRankingLoss():      \n",
        "    \n",
        "    def __init__(self, margin, score=None, summary_score=None):\n",
        "        super(MarginRankingLoss, self).__init__()\n",
        "        # self._init_param_map(score=score, summary_score=summary_score)\n",
        "        self.margin = margin\n",
        "        self.loss_func = torch.nn.MarginRankingLoss(margin)\n",
        "\n",
        "    def get_loss(self, score, summary_score):\n",
        "        \n",
        "        # equivalent to initializing TotalLoss to 0\n",
        "        # here is to avoid that some special samples will not go into the following for loop\n",
        "        ones = torch.ones(score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss = loss_func(score, score, ones)\n",
        "\n",
        "        # candidate loss\n",
        "        n = score.size(1)\n",
        "        for i in range(1, n):\n",
        "            pos_score = score[:, :-i]\n",
        "            neg_score = score[:, i:]\n",
        "            pos_score = pos_score.contiguous().view(-1)\n",
        "            neg_score = neg_score.contiguous().view(-1)\n",
        "            ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "            loss_func = torch.nn.MarginRankingLoss(self.margin * i)\n",
        "            TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "\n",
        "        # gold summary loss\n",
        "        pos_score = summary_score.unsqueeze(-1).expand_as(score)\n",
        "        neg_score = score\n",
        "        pos_score = pos_score.contiguous().view(-1)\n",
        "        neg_score = neg_score.contiguous().view(-1)\n",
        "        ones = torch.ones(pos_score.size()).cuda(score.device)\n",
        "        loss_func = torch.nn.MarginRankingLoss(0.0)\n",
        "        TotalLoss += loss_func(pos_score, neg_score, ones)\n",
        "        \n",
        "        return TotalLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKJb-DcKynhV"
      },
      "source": [
        "### Train code\n",
        "\n",
        "- Encoder -> KoBART\n",
        "- GLM 을 제외한 제일 성능 좋은 모델이고 한국어로 train이 되어 있어 선정함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DelT9Z9wfbVi",
        "outputId": "101ca26f-a93c-4362-ee0b-90fc00b9a2b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cached model. /content/.cache/kobart_base_cased_ff4bda5738.zip\n"
          ]
        }
      ],
      "source": [
        "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
        "summary_model = MatchSum(encoder = model, candidate_num = 5,device = device, hidden_size=768) \n",
        "\n",
        "N_EPOCHS = 3\n",
        "optimizer = SGD(model.parameters(),lr =0.0001)\n",
        "scheduler = CosineAnnealingLR(optimizer,T_max = len(train_dataloader)*2)\n",
        "criterion = MarginRankingLoss(margin = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502,
          "referenced_widgets": [
            "f35ebea6c94a4328a8e873e4c5056760",
            "655d3b1a616f49a4949db78986e82566",
            "f662b535deba4a098f0335caa9328153",
            "e86b277816d24015a8d79a95144cfec2",
            "171e01db5ddd4d869627936a50cfd088",
            "21b99a9c9bf44fa8b146920c6ce5918b",
            "b49427f1a02747d98c6c14a50984585a",
            "d5ffd45c1012493f81c72716c2a66f67"
          ]
        },
        "id": "KmtCKyr2D0YE",
        "outputId": "a79bc455-9968-4310-9d45-e5078e6332e5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:zu9ixchx) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f35ebea6c94a4328a8e873e4c5056760",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/loss</td><td>█▇▆▆▅▄▅▇▂▄▃▅▂▅▃▄▆▆▂▅▄▃▅▆▃▄▂▃▃▄▄▂▄▃▃▂▃▁▃▄</td></tr><tr><td>train/lr</td><td>█████▇▇▇▆▆▆▅▅▄▄▄▃▃▃▂▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▄</td></tr><tr><td>val/loss</td><td>▆▇▃▇▅█▆▁▇█▅██▃▅▄▆▃▅▃▆▄▅▂▅▄▆▅▃▅▃▂▄▄▃▄▅▃▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/loss</td><td>0.09684</td></tr><tr><td>train/lr</td><td>5e-05</td></tr><tr><td>val/loss</td><td>0.1085</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">breezy-brook-7</strong>: <a href=\"https://wandb.ai/tkdlqh2/summarization/runs/zu9ixchx\" target=\"_blank\">https://wandb.ai/tkdlqh2/summarization/runs/zu9ixchx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220322_080222-zu9ixchx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:zu9ixchx). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220322_144336-2y7tuvgd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/tkdlqh2/summarization/runs/2y7tuvgd\" target=\"_blank\">deep-feather-8</a></strong> to <a href=\"https://wandb.ai/tkdlqh2/summarization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****Epoch 0 Train Start*****\n",
            "*****Epoch 0 Total Step 3248*****\n",
            "Step: 50 Loss: 0.1057 lr: 0.0001\n",
            "Step: 100 Loss: 0.1085 lr: 0.0001\n",
            "Step: 150 Loss: 0.1096 lr: 0.0001\n",
            "Step: 200 Loss: 0.1027 lr: 0.0001\n",
            "Step: 250 Loss: 0.1047 lr: 0.0001\n",
            "Step: 300 Loss: 0.1044 lr: 0.0001\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "summary_model.to(device)\n",
        "wandb.init(project='summarization', entity='tkdlqh2')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    print(f\"*****Epoch {epoch} Train Start*****\")\n",
        "    print(f\"*****Epoch {epoch} Total Step {len(train_dataloader)}*****\")\n",
        "    total_loss, batch_loss, batch_step = 0,0,0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch_step+=1\n",
        "        text_input_ids = batch[\"text_input_ids\"].to(device)        \n",
        "        label_input_ids = batch[\"labels_input_ids\"].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        output = summary_model.forward(text_input_ids, label_input_ids,batch[\"sentence_input_ids\"])\n",
        "        loss = criterion.get_loss(score = output[\"score\"],summary_score = output[\"summary_score\"])\n",
        "\n",
        "        # loss 계산\n",
        "        loss.backward()\n",
        "        # optimizer 업데이트\n",
        "        optimizer.step()\n",
        "        # scheduler 업데이트\n",
        "        scheduler.step()\n",
        "\n",
        "        batch_loss += loss.item()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        learning_rate = optimizer.param_groups[0]['lr']\n",
        "        wandb.log({'train/lr':learning_rate,\"train/loss\":loss.item()})\n",
        "\n",
        "        if (step%50 == 0) and (step!=0):\n",
        "            print(f\"Step: {step} Loss: {batch_loss/batch_step:.4f} lr: {optimizer.param_groups[0]['lr']:.4f}\")\n",
        "            # 변수 초기화    \n",
        "            batch_loss, batch_step = 0,0\n",
        "\n",
        "    print(f\"Epoch {epoch} Total Mean Loss : {total_loss/(step+1):.4f}\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      print('**Calculating validation results...**')\n",
        "      total_val_loss,batch_step = 0,0\n",
        "      model.eval()\n",
        "      for step, batch in enumerate(valid_dataloader):\n",
        "          batch_step+=1\n",
        "          text_input_ids = batch[\"text_input_ids\"].to(device)        \n",
        "          label_input_ids = batch[\"labels_input_ids\"].to(device)\n",
        "\n",
        "          # forward\n",
        "          output = summary_model.forward(text_input_ids, label_input_ids,batch[\"sentence_input_ids\"])\n",
        "          val_loss = criterion.get_loss(score = output[\"score\"],summary_score = output[\"summary_score\"])\n",
        "\n",
        "          total_val_loss += val_loss.item()\n",
        "          wandb.log({\"val/loss\":val_loss.item()})\n",
        "\n",
        "    print(f\"Epoch {epoch} Total Mean Score : {total_val_loss/(step+1):.4f}\")\n",
        "    \n",
        "    print(f\"*****Epoch {epoch} Train Finished*****\\n\")\n",
        "    torch.save(model.state_dict(),f\"/content/drive/MyDrive/NLP/kobart_model_{epoch}epoch.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOLLs-GN6vGC"
      },
      "source": [
        "### Model-Load & Inference\n",
        "- "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jPSdEm4E14f",
        "outputId": "158658e6-2ec4-4764-e8f9-77594921011e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BartModel(\n",
            "  (shared): Embedding(30000, 768, padding_idx=3)\n",
            "  (encoder): BartEncoder(\n",
            "    (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
            "    (embed_positions): BartLearnedPositionalEmbedding(1028, 768, padding_idx=3)\n",
            "    (layers): ModuleList(\n",
            "      (0): BartEncoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): BartEncoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): BartEncoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): BartEncoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): BartEncoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): BartEncoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): BartDecoder(\n",
            "    (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
            "    (embed_positions): BartLearnedPositionalEmbedding(1028, 768, padding_idx=3)\n",
            "    (layers): ModuleList(\n",
            "      (0): BartDecoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): BartDecoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): BartDecoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): BartDecoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): BartDecoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): BartDecoderLayer(\n",
            "        (self_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): BartAttention(\n",
            "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = BartModel\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/NLP/kobart_model_2epoch.pth\")\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "qQnzGTkwiJz_",
        "outputId": "1cdbf4ab-0544-4782-f7ef-ea9d4de7132c"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-3c20cd9acbc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/NLP/kobart_model_2epoch.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_metadata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'copy'"
          ]
        }
      ],
      "source": [
        "summary_model = MatchSum(encoder = model, candidate_num = 5,device = device, hidden_size=768) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDJKJZ-Q6SuZ"
      },
      "outputs": [],
      "source": [
        "# tokenzier_for_eval = \n",
        "# model_for_eval = AutoModel.from_pretrained(\"klue/roberta-small\")\n",
        "# metric = rdass(model_for_eval,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcIcbmwnyWEZ"
      },
      "outputs": [],
      "source": [
        "class rdass:\n",
        "  def __init__(self,encoder,device):\n",
        "    self.encoder = encoder\n",
        "    for param in self.encoder.parameters():\n",
        "        param.requires_grad = False\n",
        "  \n",
        "  def __call__(self, text_ids = None, label_ids = None, answer_ids = None):\n",
        "    vector_text = self.encoder(text_ids).detach()['hidden_states'][-1][0,:] # vector_d\n",
        "    vector_label = self.encoder(label_ids).detach()['hidden_states'][-1][0,:] # vector_r\n",
        "    vector_answer = self.encoder(answer_ids).detach()['hidden_states'][-1][0,:] # vector_p\n",
        "\n",
        "    return get_score(vector_text,vector_label,vector_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBGA18fXD_aE"
      },
      "outputs": [],
      "source": [
        "trimmed_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXfMbCG2GamX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7NQTQNZdTDuO"
      ],
      "machine_shape": "hm",
      "name": "기업과제 4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "171e01db5ddd4d869627936a50cfd088": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b99a9c9bf44fa8b146920c6ce5918b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "655d3b1a616f49a4949db78986e82566": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_171e01db5ddd4d869627936a50cfd088",
            "placeholder": "​",
            "style": "IPY_MODEL_21b99a9c9bf44fa8b146920c6ce5918b",
            "value": "0.037 MB of 0.037 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b49427f1a02747d98c6c14a50984585a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ffd45c1012493f81c72716c2a66f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e86b277816d24015a8d79a95144cfec2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35ebea6c94a4328a8e873e4c5056760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_655d3b1a616f49a4949db78986e82566",
              "IPY_MODEL_f662b535deba4a098f0335caa9328153"
            ],
            "layout": "IPY_MODEL_e86b277816d24015a8d79a95144cfec2"
          }
        },
        "f662b535deba4a098f0335caa9328153": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b49427f1a02747d98c6c14a50984585a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5ffd45c1012493f81c72716c2a66f67",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
